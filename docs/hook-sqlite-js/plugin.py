import os
import shutil
import sqlite3
import re
import logging
import hashlib
import json
from mkdocs.plugins import BasePlugin
from bs4 import BeautifulSoup
from lxml import html
from html import escape
from html.parser import HTMLParser
import warnings

# ==================== é…ç½®é€‰é¡¹ ====================
# âš™ï¸ ç›´æ¥åœ¨ä»£ç ä¸­é…ç½®æœç´¢åŠŸèƒ½ï¼ˆæ–¹ä¾¿å¿«é€Ÿä¿®æ”¹ï¼‰
# è®¾ç½®ä¸º True å¯ç”¨æœ¬åœ°æœç´¢ï¼ŒFalse ç¦ç”¨æœ¬åœ°æœç´¢
LOCAL_SEARCH_ENABLED = False # ğŸ”§ åœ¨è¿™é‡Œç›´æ¥ä¿®æ”¹ï¼šTrue=å¯ç”¨ï¼ŒFalse=ç¦ç”¨

# æœç´¢åŠŸèƒ½å¼€å…³é…ç½®ï¼ˆä¾¿äºå¼€å‘æ—¶å¿«é€Ÿç¦ç”¨ï¼‰
ENABLE_SEARCH = os.environ.get('MKDOCS_ENABLE_SEARCH', 'true').lower() == 'true'

# å¼€å‘æ¨¡å¼æ£€æµ‹ï¼ˆè·³è¿‡é‡å»ºä»¥æå‡å¼€å‘é€Ÿåº¦ï¼‰
DEV_MODE_SKIP_REBUILD = os.environ.get('MKDOCS_DEV_SKIP_REBUILD', 'true').lower() == 'true'

# GitHub CI/CD ç¯å¢ƒæ£€æµ‹ï¼ˆåœ¨ GitHub Actions ä¸­è‡ªåŠ¨å¯ç”¨æœç´¢ï¼‰
def is_github_actions():
    """æ£€æµ‹æ˜¯å¦åœ¨ GitHub Actions ç¯å¢ƒä¸­è¿è¡Œ"""
    return (
        os.environ.get('GITHUB_ACTIONS') == 'true' or
        os.environ.get('CI') == 'true' or
        os.environ.get('GITHUB_WORKFLOW') is not None
    )

# æœ¬åœ°å¼€å‘æ—¶æ ¹æ®é…ç½®å¯ç”¨/ç¦ç”¨ï¼ŒGitHub Actions æ—¶è‡ªåŠ¨å¯ç”¨
def should_enable_search():
    """æ™ºèƒ½åˆ¤æ–­æ˜¯å¦å¯ç”¨æœç´¢åŠŸèƒ½"""
    # 1. å¦‚æœæ˜ç¡®è®¾ç½®äº†ç¯å¢ƒå˜é‡ï¼Œä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡
    if 'MKDOCS_ENABLE_SEARCH' in os.environ:
        enabled = os.environ.get('MKDOCS_ENABLE_SEARCH', 'false').lower() == 'true'
        return enabled
    
    # 2. å¦‚æœåœ¨ GitHub Actions ç¯å¢ƒä¸­ï¼Œè‡ªåŠ¨å¯ç”¨
    if is_github_actions():
        return True
    
    # 3. ä½¿ç”¨æœ¬åœ°é…ç½®è®¾ç½®
    return LOCAL_SEARCH_ENABLED

# ä½¿ç”¨æ™ºèƒ½æ£€æµ‹
ENABLE_SEARCH = should_enable_search()

# è°ƒè¯•æ¨¡å¼
DEBUG_MODE = os.environ.get('MKDOCS_DEBUG', 'false').lower() == 'true'

def print_search_status():
    """æ‰“å°æœç´¢åŠŸèƒ½çŠ¶æ€ï¼ˆç®€æ´ç‰ˆï¼‰"""
    if ENABLE_SEARCH:
        if is_github_actions():
            print("ğŸ” æœç´¢åŠŸèƒ½: âœ… å¯ç”¨ (CI/CD è‡ªåŠ¨å¯ç”¨)")
        elif 'MKDOCS_ENABLE_SEARCH' in os.environ:
            print("ğŸ” æœç´¢åŠŸèƒ½: âœ… å¯ç”¨ (ç¯å¢ƒå˜é‡)")
        else:
            print("ğŸ” æœç´¢åŠŸèƒ½: âœ… å¯ç”¨ (æœ¬åœ°é…ç½®)")
    else:
        print("ğŸ” æœç´¢åŠŸèƒ½: âŒ ç¦ç”¨")
        if not LOCAL_SEARCH_ENABLED:
            print("   ğŸ’¡ è¦å¯ç”¨: ä¿®æ”¹ LOCAL_SEARCH_ENABLED = True")
        print("   ğŸ’¡ æˆ–ä½¿ç”¨: MKDOCS_ENABLE_SEARCH=true mkdocs serve")

# ==================== å…¨å±€å˜é‡ ====================
# æŠ‘åˆ¶æ‰€æœ‰ç›¸å…³è­¦å‘Š
warnings.filterwarnings("ignore", category=UserWarning, module='bs4')
warnings.filterwarnings("ignore", category=DeprecationWarning)
warnings.filterwarnings("ignore", message=".*strip_cdata.*")

MKDOCS_DOCS_PATH = None
MKDOCS_SITE_PATH = None
SQLITE_FILE_PATH = None
CACHE_FILE_PATH = None

# è®¾ç½®æ—¥å¿—çº§åˆ«
log_level = logging.DEBUG if DEBUG_MODE else logging.ERROR
logging.basicConfig(level=log_level, format='%(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def debug_print(message):
    """è°ƒè¯•æ‰“å°å‡½æ•°"""
    if DEBUG_MODE:
        print(f"ğŸ”§ DEBUG: {message}")

def calculate_file_hash(file_path):
    """è®¡ç®—æ–‡ä»¶çš„MD5å“ˆå¸Œå€¼"""
    try:
        with open(file_path, 'rb') as f:
            return hashlib.md5(f.read()).hexdigest()
    except:
        return None

def load_file_cache():
    """åŠ è½½æ–‡ä»¶ç¼“å­˜"""
    if not CACHE_FILE_PATH or not os.path.exists(CACHE_FILE_PATH):
        return {}
    try:
        with open(CACHE_FILE_PATH, 'r', encoding='utf-8') as f:
            return json.load(f)
    except:
        return {}

def save_file_cache(cache):
    """ä¿å­˜æ–‡ä»¶ç¼“å­˜"""
    if not CACHE_FILE_PATH:
        return
    try:
        os.makedirs(os.path.dirname(CACHE_FILE_PATH), exist_ok=True)
        with open(CACHE_FILE_PATH, 'w', encoding='utf-8') as f:
            json.dump(cache, f, ensure_ascii=False, indent=2)
    except Exception as e:
        logger.warning(f"ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")

def get_changed_files(site_path):
    """è·å–å˜æ›´çš„HTMLæ–‡ä»¶åˆ—è¡¨"""
    cache = load_file_cache()
    changed_files = []
    current_files = {}
    
    # æ‰«ææ‰€æœ‰HTMLæ–‡ä»¶
    for root, dirs, files in os.walk(site_path):
        for file in files:
            if file.endswith('.html'):
                file_path = os.path.join(root, file)
                file_hash = calculate_file_hash(file_path)
                rel_path = os.path.relpath(file_path, site_path)
                current_files[rel_path] = file_hash
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºæ–°æ–‡ä»¶æˆ–å·²å˜æ›´æ–‡ä»¶
                if rel_path not in cache or cache[rel_path] != file_hash:
                    changed_files.append(file_path)
    
    # ä¿å­˜æ–°çš„ç¼“å­˜
    save_file_cache(current_files)
    
    return changed_files, len(current_files)

def clean_text_for_search(text):
    """æ¸…ç†æ–‡æœ¬ç”¨äºæœç´¢ï¼Œä¿ç•™æ›´å¤šæ ¼å¼ä¿¡æ¯"""
    if not text:
        return ""
    try:
        soup = BeautifulSoup(text, 'lxml')
        text = soup.get_text(separator=' ', strip=True)
        # æ›´å½»åº•åœ°æ¸…ç†Markdownè¯­æ³•
        text = re.sub(r'\*\*(.*?)\*\*', r'\1', text)  # ç§»é™¤åŠ ç²—æ ‡è®°
        text = re.sub(r'\*(.*?)\*', r'\1', text)      # ç§»é™¤æ–œä½“æ ‡è®°
        text = re.sub(r'`(.*?)`', r'\1', text)        # ç§»é™¤è¡Œå†…ä»£ç æ ‡è®°
        text = re.sub(r'~~(.*?)~~', r'\1', text)      # ç§»é™¤åˆ é™¤çº¿æ ‡è®°
        text = re.sub(r'_{2}(.*?)_{2}', r'\1', text)  # ç§»é™¤ä¸‹åˆ’çº¿åŠ ç²—
        text = re.sub(r'_(.*?)_', r'\1', text)        # ç§»é™¤ä¸‹åˆ’çº¿æ–œä½“
        text = re.sub(r'\[(.*?)\]\(.*?\)', r'\1', text) # ç§»é™¤é“¾æ¥ï¼Œä¿ç•™æ–‡æœ¬
        text = re.sub(r'#{1,6}\s*(.*)', r'\1', text)  # ç§»é™¤æ ‡é¢˜æ ‡è®°
        # æ¸…ç†ç‰¹æ®Šç¬¦å·ï¼Œä½†ä¿ç•™ä¸­æ–‡æ ‡ç‚¹
        text = re.sub(r'[ï¼š:]\s*', ' ', text)  # å¤„ç†å†’å·
        text = re.sub(r'[ï¼Œ,]\s*', ' ', text)  # å¤„ç†é€—å·
        text = re.sub(r'[ã€‚.]\s*', ' ', text)  # å¤„ç†å¥å·
        text = re.sub(r'\s+', ' ', text)
        return text.strip()
    except Exception as e:
        logger.warning(f"è§£ææ–‡æœ¬æ—¶å‡ºé”™: {e}")
        return text.strip() if text else ""

def extract_raw_content(text):
    """æå–åŸå§‹å†…å®¹ï¼Œä¿ç•™ç‰¹æ®Šå­—ç¬¦å’Œæ ¼å¼"""
    if not text:
        return ""
    try:
        soup = BeautifulSoup(text, 'lxml')
        # ç§»é™¤scriptå’Œstyleæ ‡ç­¾
        for script in soup(["script", "style"]):
            script.decompose()
        # è·å–æ–‡æœ¬ä½†ä¿ç•™æ›´å¤šåŸå§‹æ ¼å¼
        text = soup.get_text(separator='\n', strip=True)
        # æ›´å½»åº•åœ°æ¸…ç†Markdownè¯­æ³•
        text = re.sub(r'\*\*(.*?)\*\*', r'\1', text)  # ç§»é™¤åŠ ç²—æ ‡è®°
        text = re.sub(r'\*(.*?)\*', r'\1', text)      # ç§»é™¤æ–œä½“æ ‡è®°
        text = re.sub(r'`(.*?)`', r'\1', text)        # ç§»é™¤è¡Œå†…ä»£ç æ ‡è®°
        text = re.sub(r'~~(.*?)~~', r'\1', text)      # ç§»é™¤åˆ é™¤çº¿æ ‡è®°
        text = re.sub(r'_{2}(.*?)_{2}', r'\1', text)  # ç§»é™¤ä¸‹åˆ’çº¿åŠ ç²—
        text = re.sub(r'_(.*?)_', r'\1', text)        # ç§»é™¤ä¸‹åˆ’çº¿æ–œä½“
        text = re.sub(r'\[(.*?)\]\(.*?\)', r'\1', text) # ç§»é™¤é“¾æ¥ï¼Œä¿ç•™æ–‡æœ¬
        text = re.sub(r'#{1,6}\s*(.*)', r'\1', text)  # ç§»é™¤æ ‡é¢˜æ ‡è®°
        # æ¸…ç†ç‰¹æ®Šç¬¦å·ï¼Œä½†ä¿ç•™ä¸­æ–‡æ ‡ç‚¹
        text = re.sub(r'[ï¼š:]\s*', ' ', text)  # å¤„ç†å†’å·
        text = re.sub(r'[ï¼Œ,]\s*', ' ', text)  # å¤„ç†é€—å·
        text = re.sub(r'[ã€‚.]\s*', ' ', text)  # å¤„ç†å¥å·
        # ä¿ç•™é‡è¦çš„ç‰¹æ®Šå­—ç¬¦
        text = re.sub(r'\n+', '\n', text)
        return text.strip()
    except:
        return text.strip() if text else ""

def sqlite_index_html_content(html_path: str) -> list:
    """
    ä»HTMLæ–‡ä»¶ä¸­æå–å†…å®¹å¹¶å»ºç«‹ç´¢å¼•
    
    Args:
        html_path: HTMLæ–‡ä»¶è·¯å¾„
    Returns:
        åŒ…å«ç´¢å¼•å†…å®¹çš„åˆ—è¡¨
    """
    global MKDOCS_DOCS_PATH, MKDOCS_SITE_PATH
    
    # è¯»å–HTMLå†…å®¹
    html_content = _read_html_file(html_path)
    if not html_content:
        return []
    
    # è§£æHTML
    soup = _parse_html_content(html_content)
    if not soup:
        return []
        
    # è·å–ä¸»è¦å†…å®¹åŒºåŸŸ
    content_inner = _get_content_inner(soup)
    if not content_inner:
        return []
    
    # æ¸…ç†ä¸éœ€è¦çš„å…ƒç´ 
    _clean_content(content_inner)
    
    # è·å–URLå’Œé¡µé¢åç§°
    url, name = _get_url_and_name(html_path, soup)
    
    # å¤„ç†å›¾ç‰‡å…ƒç´ 
    _process_images(content_inner, url)
    
    # æå–æ ‡é¢˜å’Œå†…å®¹
    return _extract_headings(content_inner, url, name)

def _read_html_file(html_path: str) -> str:
    """è¯»å–HTMLæ–‡ä»¶å†…å®¹"""
    try:
        with open(html_path, 'r', encoding='utf-8') as f:
            return f.read()
    except Exception:
        return ''

def _parse_html_content(html_content: str) -> BeautifulSoup | None:
    """è§£æHTMLå†…å®¹"""
    try:
        return BeautifulSoup(html_content, 'lxml')
    except Exception:
        try:
            return BeautifulSoup(html_content, 'html.parser')
        except Exception:
            return None

def _get_content_inner(soup: BeautifulSoup):
    """è·å–ä¸»è¦å†…å®¹åŒºåŸŸ"""
    content_inner = soup.find(class_='md-content__inner')
    if not content_inner or not hasattr(content_inner, 'find_all'):
        return None
    return content_inner

def _clean_content(content_inner):
    """æ¸…ç†ä¸éœ€è¦çš„å…ƒç´ """
    for element in content_inner.find_all(['script', 'style', 'object']):
        if hasattr(element, 'decompose'):
            element.decompose()
    for linenos in content_inner.select('.md-content .linenos'):
        linenos.decompose()

def _get_url_and_name(html_path: str, soup: BeautifulSoup) -> tuple:
    """è·å–URLå’Œé¡µé¢åç§°"""
    global MKDOCS_SITE_PATH
    html_url_relpath = os.path.relpath(html_path, MKDOCS_SITE_PATH)
    url = html_url_relpath.replace(os.sep, "/")
    
    # ä¼˜å…ˆä»HTMLçš„<title>æ ‡ç­¾è·å–é¡µé¢åç§°
    try:
        title_tag = soup.find('title')
        if title_tag:
            name = title_tag.get_text(strip=True)
            # ç§»é™¤mkdocsæ·»åŠ çš„ç«™ç‚¹åç§°åç¼€
            name = re.sub(r'\s+-\s+.*$', '', name, 1)
        else:
            raise ValueError("No title tag found")
    except Exception:
        # å›é€€åˆ°ä»è·¯å¾„ç”Ÿæˆåç§°
        path_for_name = url
        if path_for_name.endswith('/index.html'):
            path_for_name = path_for_name[:-11]
        elif path_for_name == 'index.html':
            path_for_name = ''
        name = path_for_name.split('/')[-1] if path_for_name else "ä¸»é¡µ"

    # æ¸…ç†URLï¼Œç§»é™¤ index.html
    if url.endswith('/index.html'):
        url = url[:-10]  # ä¿ç•™æœ«å°¾çš„'/'
    elif url == 'index.html':
        url = '/'
    
    # ç¡®ä¿URLä»¥'/'å¼€å¤´
    if not url.startswith('/'):
        url = '/' + url

    return url, name

def _process_images(content_inner, url: str):
    """å¤„ç†å›¾ç‰‡å…ƒç´ """
    for img in content_inner.select('img'):
        try:
            img_src = img.get('src', '')
            if img_src:
                img_url = f"{url.rstrip('/')}/{img_src}" if url != '/' else f"/{img_src}"
                button_html = f'<a href="{escape(img_url)}" target="_blank"><button>æŸ¥çœ‹å›¾ç‰‡</button></a>'
                img.replace_with(BeautifulSoup(button_html, 'lxml'))
        except Exception:
            img.decompose()

def _extract_headings(content_inner, url: str, name: str) -> list:
    """æå–æ ‡é¢˜å’Œå†…å®¹"""
    headings = []
    current_title = None
    
    # ä¸ºæ•´ä¸ªé¡µé¢åˆ›å»ºä¸€ä¸ªæ–‡æ¡£
    page_body = str(content_inner)
    headings.append({
        'url': url,
        'name': name,
        'title': name, # é¡µé¢ä¸»æ ‡é¢˜
        'link': '', # æŒ‡å‘é¡µé¢æœ¬èº«
        'body': page_body,
    })

    for element in content_inner.children:
        if _is_heading_element(element):
            title_id = element.attrs.get('id', '') if hasattr(element, 'attrs') else ''
            title_text = element.get_text(strip=True).rstrip("Â¶")
            if title_text:
                headings.append({
                    'url': url,
                    'name': name,
                    'title': title_text,
                    'link': f"#{title_id}" if title_id else "",
                    'body': str(element.find_next_sibling()) if element.find_next_sibling() else ''
                })
    
    return headings

def _is_heading_element(element) -> bool:
    """åˆ¤æ–­æ˜¯å¦ä¸ºæ ‡é¢˜å…ƒç´ """
    return (hasattr(element, 'name') and 
            hasattr(element, 'find_all') and 
            element.name and 
            element.name.startswith('h'))

def sqlite_index_all_html_files(dir_path: str) -> list:
    print("ğŸ“ æ­£åœ¨ç´¢å¼•æ–‡æ¡£...")
    html_file_paths = []
    for root, dirs, files in os.walk(dir_path):
        for file in files:
            if file.endswith('.html'):
                html_path = os.path.join(root, file)
                html_file_paths.append(html_path)
    
    docs = []
    for html_path in html_file_paths:
        headings = sqlite_index_html_content(html_path)
        if headings:
            docs.extend(headings)
    
    print(f"âœ… ç´¢å¼•å®Œæˆ: {len(docs)} ä¸ªæ–‡æ¡£")
    return docs

def sqlite_create_db_and_insert_data(db_path, datas, table_name='mkdocs'):
    db_directory = os.path.dirname(db_path)
    if not os.path.exists(db_directory):
        os.makedirs(db_directory)
    
    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        cursor.execute(f'DROP TABLE IF EXISTS {table_name};')
        
        cursor.execute(f'''
            CREATE TABLE {table_name} (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                url TEXT NOT NULL,
                name TEXT NOT NULL,
                title TEXT NOT NULL,
                link TEXT NOT NULL,
                body TEXT,
                raw_content TEXT,
                search_text TEXT
            )
        ''')
        
        insert_data = []
        for data in datas:
            raw_content = extract_raw_content(data['body'])
            search_text = f"{data['title']} {clean_text_for_search(data['body'])} {raw_content}"
            insert_data.append((
                data['url'],
                data['name'],
                data['title'],
                data['link'],
                data['body'],
                raw_content,
                search_text
            ))
        
        cursor.executemany(f'''
            INSERT INTO {table_name} (url, name, title, link, body, raw_content, search_text)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        ''', insert_data)
        conn.commit()
        print(f"ğŸ’¾ æ•°æ®åº“å°±ç»ª: {len(insert_data)} æ¡è®°å½•")
    except Exception as e:
        logger.error(f"æ•°æ®åº“æ“ä½œå¤±è´¥: {e}")
        if conn:
            conn.rollback()
        raise
    finally:
        if conn:
            conn.close()

def sqlite_index_changed_files(changed_files, db_path):
    """åªç´¢å¼•å˜æ›´çš„æ–‡ä»¶"""
    if not changed_files:
        print("ğŸ“„ æ— æ–‡ä»¶å˜æ›´ï¼Œè·³è¿‡ç´¢å¼•")
        return
    
    print(f"ğŸ“ å¢é‡ç´¢å¼•: {len(changed_files)} ä¸ªæ–‡ä»¶")
    
    docs = []
    for html_path in changed_files:
        headings = sqlite_index_html_content(html_path)
        if headings:
            docs.extend(headings)
    
    if not docs:
        print("ğŸ“„ æ— æ–°å†…å®¹")
        return
    
    # æ›´æ–°æ•°æ®åº“
    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # åˆ é™¤å˜æ›´æ–‡ä»¶çš„æ—§è®°å½•
        for html_path in changed_files:
            html_url_relpath = os.path.relpath(html_path, MKDOCS_SITE_PATH)
            url = html_url_relpath.replace(os.sep, "/")
            
            # å¤„ç†URLæ ¼å¼
            if url.endswith('/index.html'):
                url = url[:-10]
            elif url == 'index.html':
                url = '/'
            
            if not url.startswith('/'):
                url = '/' + url
                
            cursor.execute("DELETE FROM mkdocs WHERE url = ?", (url,))
        
        # æ’å…¥æ–°è®°å½•
        insert_data = []
        for data in docs:
            raw_content = extract_raw_content(data['body'])
            search_text = f"{data['title']} {clean_text_for_search(data['body'])} {raw_content}"
            insert_data.append((
                data['url'],
                data['name'],
                data['title'],
                data['link'],
                data['body'],
                raw_content,
                search_text
            ))
        
        cursor.executemany('''
            INSERT INTO mkdocs (url, name, title, link, body, raw_content, search_text)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        ''', insert_data)
        
        conn.commit()
        print(f"ğŸ’¾ å¢é‡æ›´æ–°å®Œæˆ: {len(insert_data)} æ¡è®°å½•")
        
    except Exception as e:
        logger.error(f"å¢é‡æ›´æ–°å¤±è´¥: {e}")
        if conn:
            conn.rollback()
        # å¦‚æœå¢é‡æ›´æ–°å¤±è´¥ï¼Œå›é€€åˆ°å…¨é‡é‡å»º
        print("âš ï¸ å¢é‡æ›´æ–°å¤±è´¥ï¼Œå›é€€å…¨é‡é‡å»º...")
        docs = sqlite_index_all_html_files(MKDOCS_SITE_PATH)
        sqlite_create_db_and_insert_data(SQLITE_FILE_PATH, docs)
    finally:
        if conn:
            conn.close()

def on_config(config):
    global MKDOCS_DOCS_PATH, MKDOCS_SITE_PATH, SQLITE_FILE_PATH, CACHE_FILE_PATH
    
    # æ‰“å°ç®€æ´çš„æœç´¢åŠŸèƒ½çŠ¶æ€
    print_search_status()
    
    MKDOCS_DOCS_PATH = config['docs_dir']
    MKDOCS_SITE_PATH = config['site_dir']
    SQLITE_FILE_PATH = os.path.join(config.site_dir, "search", "database.sqlite")
    
    # å°†ç¼“å­˜æ–‡ä»¶æ”¾åˆ°é¡¹ç›®æ ¹ç›®å½•ï¼Œé¿å…è¢«æ¸…ç†
    project_root = os.path.dirname(config.config_file_path or os.getcwd())
    cache_dir = os.path.join(project_root, ".mkdocs_cache")
    CACHE_FILE_PATH = os.path.join(cache_dir, "search_file_cache.json")
    
    # ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
    os.makedirs(cache_dir, exist_ok=True)

def on_page_content(html, page, config, files):
    """é¡µé¢å†…å®¹å¤„ç†é’©å­"""
    # å¦‚æœæœç´¢åŠŸèƒ½è¢«ç¦ç”¨ï¼Œä¸æ·»åŠ æœç´¢è„šæœ¬
    if not ENABLE_SEARCH:
        return html
    
    script_code = """
    <script src="/search/sql-wasm.js"></script>
    <script>
        document.addEventListener('DOMContentLoaded', function () {
            var nav = document.querySelector('nav.md-header__inner.md-grid')
            var new_content = `
                <!-- ============ æ–°æ’å…¥çš„ ======================== -->
                <!-- ç§»åŠ¨ç«¯çš„ æœç´¢æŒ‰é’®å›¾æ ‡ -->
                <label class="md-header__button md-icon" for="__search">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
                </label>
                <!-- ç”µè„‘ç«¯ æœç´¢æŒ‰é’®è¾“å…¥æ¡† -->
                <div class="md-search" data-md-component="search" role="dialog">
                    <!-- æœç´¢æ¡† > é®æŒ¡åŒºåŸŸ, ç”¨äºç‚¹å‡»ä»»æ„åŒºåŸŸ é€€å‡º æœç´¢ç»“æœçš„æ˜¾ç¤º -->
                    <label class="md-search__overlay" for="__search"></label>
                    <div class="md-search__inner" role="search">
                        <form class="md-search__form" name="search">
                            <!-- æœç´¢æ¡† > æ–‡æœ¬è¾“å…¥åŒºåŸŸ -->
                            <input type="text" class="md-search__input" name="query" aria-label="æœç´¢" placeholder="æœç´¢" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required="">
                            <!-- æœç´¢æ¡† > æ”¾å¤§é•œå›¾æ ‡, åªæ˜¯å›¾æ ‡ ä¸èƒ½ç‚¹å‡» -->
                            <label class="md-search__icon md-icon" for="__search">
                                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
                                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg>
                            </label>
                            <!-- æœç´¢æ¡† > æ¸…é™¤æŒ‰é’®, é»˜è®¤: aria-label="æŸ¥æ‰¾" -->
                            <nav class="md-search__options" aria-label="æ¸…é™¤">
                                <button type="reset" class="md-search__icon md-icon" title="æ¸…ç©ºå½“å‰å†…å®¹" aria-label="æ¸…ç©ºå½“å‰å†…å®¹" tabindex="-1">
                                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg>
                                </button>
                            </nav>
                        </form>
                        <!-- æœç´¢ç»“æœæ˜¾ç¤ºçš„å†…å®¹ -->
                        <div class="md-search__output">
                            <div class="md-search__scrollwrap" tabindex="0">
                                <div class="md-search-result" data-md-component="search-result">
                                    <!-- æœç´¢ç»“æœ > æœç´¢ç»“æœä¿¡æ¯çš„æç¤º -->
                                    <div class="md-search-result__meta">é”®å…¥ä»¥å¼€å§‹æœç´¢</div>
                                    <!-- æœç´¢ç»“æœ > çœŸæ­£çš„ç»“æœ List å®¹å™¨, å­å…ƒç´ ä¸º li.md-search-result__item -->
                                    <ol class="md-search-result__list" role="presentation"></ol>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
                <style>
                    /* æœç´¢åŠŸèƒ½ > æ˜¾ç¤ºçš„å†…å®¹ > é¡µé¢x çš„å†…å®¹éƒ¨åˆ† > ä¿®å¤å¤§å±æ—¶å·¦è¾¹è·è¿‡å¤§, å½±å“è§†è§‰ */
                    @media screen and (min-width: 60em) {
                        /* é’ˆå¯¹åç»­çš„ articleï¼ˆæœç´¢ç»“æœï¼‰, ä½¿ç”¨cssé€‰æ‹©å™¨, ä» */
                        ol.md-search-result__list li.md-search-result__item a article:nth-child(n+2)  {
                            padding-left: 0.8rem;
                        }
                    }
                    /* æœç´¢å…³é”®è¯é«˜äº®æ ·å¼ */
                    .search-highlight {
                        background-color: #ffeb3b;
                        color: #000;
                        padding: 1px 2px;
                        border-radius: 2px;
                        font-weight: 500;
                    }
                    /* æ·±è‰²ä¸»é¢˜ä¸‹çš„é«˜äº®æ ·å¼ */
                    [data-md-color-scheme="slate"] .search-highlight {
                        background-color: #ffa726;
                        color: #000;
                    }
                    /* æœç´¢ç»“æœæ ‡é¢˜é«˜äº® */
                    .md-search-result__article h1 .search-highlight,
                    .md-search-result__article h2 .search-highlight {
                        background-color: #4caf50;
                        color: #fff;
                    }
                    /* æ·±è‰²ä¸»é¢˜ä¸‹æ ‡é¢˜é«˜äº® */
                    [data-md_color-scheme="slate"] .md-search-result__article h1 .search-highlight,
                    [data-md_color-scheme="slate"] .md-search-result__article h2 .search-highlight {
                        background-color: #66bb6a;
                        color: #000;
                    }
                </style>
                `
            // æŸ¥æ‰¾ä»“åº“é“¾æ¥å…ƒç´ 
            var repoElement = nav.querySelector('.md-header__source');
            if (repoElement) {
                // å¦‚æœæ‰¾åˆ°ä»“åº“é“¾æ¥ï¼Œåœ¨å®ƒä¹‹å‰æ’å…¥æœç´¢æ¡†
                repoElement.insertAdjacentHTML('beforebegin', new_content);
            } else {
                // å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»“åº“é“¾æ¥ï¼Œåœ¨navçš„æœ€åé¢æ’å…¥
                nav.insertAdjacentHTML('beforeend', new_content);
            }
            var search_input = nav.querySelector('.md-search .md-search__inner .md-search__form .md-search__input')
            var toggle = document.querySelector(
                'input.md-toggle[data-md-toggle="search"]'
            )
            search_input.addEventListener('focus', function () {
                this.classList.add('focus-visible')
                this.setAttribute('data-focus-visible-added', '')
                toggle.checked = true
            })
        });

        document.addEventListener('DOMContentLoaded', async function () {
            var search_input = document.querySelector('.md-search .md-search__inner .md-search__form .md-search__input')
            var search_info = document.querySelector('.md-search-result__meta')
            var resultList = document.querySelector('.md-search-result__list')
            let debounceTimeout;
            let currentSearchQuery = '';
            const sqlPromise = initSqlJs({
                locateFile: file => `/search/${file}`
            });
            const dataPromise = fetch("/search/database.sqlite").then(res => res.arrayBuffer());
            const [SQL, buf] = await Promise.all([sqlPromise, dataPromise])
            const db = new SQL.Database(new Uint8Array(buf));
            const clearButton = document.querySelector('.md-search .md-search__inner .md-search__form .md-search__icon.md-icon');
            clearButton.addEventListener('click', function() {
                resultList.innerHTML = '';
                search_input.value = '';
                currentSearchQuery = '';
                search_input.focus();
            });
            
            function normalizeQuery(query) {
                // æ¸…ç†æŸ¥è¯¢å­—ç¬¦ä¸²ï¼Œå¤„ç†å„ç§æ ‡ç‚¹ç¬¦å·
                return query
                    .replace(/[ï¼š:]/g, ' ')      // å†’å·æ›¿æ¢ä¸ºç©ºæ ¼
                    .replace(/[ï¼Œ,]/g, ' ')      // é€—å·æ›¿æ¢ä¸ºç©ºæ ¼
                    .replace(/[ã€‚.]/g, ' ')      // å¥å·æ›¿æ¢ä¸ºç©ºæ ¼
                    .replace(/[ï¼!]/g, ' ')      // æ„Ÿå¹å·æ›¿æ¢ä¸ºç©ºæ ¼
                    .replace(/[ï¼Ÿ?]/g, ' ')      // é—®å·æ›¿æ¢ä¸ºç©ºæ ¼
                    .replace(/[ï¼›;]/g, ' ')      // åˆ†å·æ›¿æ¢ä¸ºç©ºæ ¼
                    .replace(/\\s+/g, ' ')       // å¤šä¸ªç©ºæ ¼åˆå¹¶ä¸ºä¸€ä¸ª
                    .trim();
            }
            
            function highlightKeywords(text, keywords) {
                if (!keywords || !text) return escapeHtml(text);
                const keywordList = keywords.split(/\\s+/).filter(k => k.trim().length > 0);
                if (keywordList.length === 0) return escapeHtml(text);
                let highlightedText = escapeHtml(text);
                keywordList.forEach(keyword => {
                    const escapedKeyword = keyword.replace(/[.*+?^${}()|[\\]\\\\]/g, '\\\\$&');
                    const regex = new RegExp(`(${escapedKeyword})`, 'gi');
                    highlightedText = highlightedText.replace(regex, '<span class="search-highlight">$1</span>');
                });
                return highlightedText;
            }
            function escapeHtml(text) {
                const div = document.createElement('div');
                div.textContent = text;
                return div.innerHTML;
            }
            function truncateAndHighlight(content, rawContent, maxLength, keywords) {
                if (!content && !rawContent) return '';
                
                // ä¼˜å…ˆä½¿ç”¨åŸå§‹å†…å®¹è¿›è¡ŒåŒ¹é…
                const keywordList = keywords.split(/\\s+/).filter(k => k.trim().length > 0);
                let bestContent = rawContent || content;
                let bestMatch = -1;
                
                const textToSearch = (rawContent || (content ? new DOMParser().parseFromString(content, "text/html").body.textContent : "")).toLowerCase();

                for (const keyword of keywordList) {
                    const index = textToSearch.indexOf(keyword.toLowerCase());
                    if (index !== -1) {
                        bestMatch = index;
                        break;
                    }
                }
                
                let finalText = textToSearch;
                
                let truncatedText = finalText;
                if (finalText.length > maxLength) {
                    let bestStart = 0;
                    if (bestMatch !== -1) {
                        bestStart = Math.max(0, bestMatch - Math.floor(maxLength / 3));
                    }
                    truncatedText = finalText.substring(bestStart, bestStart + maxLength);
                    if (bestStart > 0) truncatedText = '...' + truncatedText;
                    if (bestStart + maxLength < finalText.length) truncatedText += '...';
                }
                
                return highlightKeywords(truncatedText, keywords);
            }
            search_input.addEventListener('input', function () {
                if(!db){
                    search_info.textContent = 'æ­£åœ¨åˆå§‹åŒ–ä¸­...'
                    return;
                }
                var search_query = this.value.trim(); // å»é™¤é¦–å°¾ç©ºç™½
                currentSearchQuery = search_query;
                if (!search_query) {
                    search_info.textContent = 'é”®å…¥ä»¥å¼€å§‹æœç´¢'
                    resultList.innerHTML = '';
                    return
                }
                if (search_query.length < 2) {
                    search_info.textContent = 'è¯·è¾“å…¥2ä¸ªä»¥ä¸Šçš„å­—ç¬¦'
                    return
                }
                if (debounceTimeout) clearTimeout(debounceTimeout);
                debounceTimeout = setTimeout(function () {
                    if (!search_query) {
                        search_info.textContent = 'é”®å…¥ä»¥å¼€å§‹æœç´¢';
                        return;
                    }
                    if (search_query.length < 2) {
                        search_info.textContent = 'è¯·è¾“å…¥2ä¸ªä»¥ä¸Šçš„å­—ç¬¦';
                        return;
                    }
                    try {
                        // æ ‡å‡†åŒ–æŸ¥è¯¢å­—ç¬¦ä¸²
                        const normalizedQuery = normalizeQuery(search_query);
                        const keywords = normalizedQuery.split(/\\s+/).filter(k => k.trim().length >= 1);
                        
                        if (keywords.length === 0) return;

                        // æ”¹è¿›çš„æœç´¢ç­–ç•¥ï¼šä½¿ç”¨ORé€»è¾‘è€Œä¸æ˜¯ANDé€»è¾‘
                        let queryParts = [];
                        let params = [];
                        
                        // å®Œæ•´æŸ¥è¯¢åŒ¹é…ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
                        queryParts.push("(title LIKE ? OR search_text LIKE ?)");
                        params.push(`%${search_query}%`, `%${search_query}%`);
                        
                        // æ ‡å‡†åŒ–æŸ¥è¯¢åŒ¹é…
                        if (normalizedQuery !== search_query) {
                            queryParts.push("(title LIKE ? OR search_text LIKE ?)");
                            params.push(`%${normalizedQuery}%`, `%${normalizedQuery}%`);
                        }
                        
                        // å•ä¸ªå…³é”®è¯åŒ¹é…
                        keywords.forEach(kw => {
                            if (kw.length >= 2) {
                                queryParts.push("(title LIKE ? OR search_text LIKE ?)");
                                params.push(`%${kw}%`, `%${kw}%`);
                            }
                        });
                        
                        const sqlQuery = `SELECT * FROM mkdocs WHERE ${queryParts.join(' OR ')}`;
                        const stmt = db.prepare(sqlQuery);
                        stmt.bind(params);
                        
                        const results = new Map();
                        while (stmt.step()) {
                            const row = stmt.getAsObject();
                            
                            let score = 0;
                            const lowerQuery = search_query.toLowerCase();
                            const lowerNormalizedQuery = normalizedQuery.toLowerCase();
                            const lowerTitle = (row.title || '').toLowerCase();
                            const lowerContent = (row.raw_content || '').toLowerCase();
                            const lowerSearchText = (row.search_text || '').toLowerCase();

                            // å®Œæ•´æŸ¥è¯¢åŒ¹é…ï¼ˆæœ€é«˜åˆ†ï¼‰
                            if (lowerTitle.includes(lowerQuery)) score += 100;
                            if (lowerSearchText.includes(lowerQuery)) score += 80;
                            
                            // æ ‡å‡†åŒ–æŸ¥è¯¢åŒ¹é…
                            if (lowerTitle.includes(lowerNormalizedQuery)) score += 90;
                            if (lowerSearchText.includes(lowerNormalizedQuery)) score += 70;
                            
                            // æ ‡é¢˜å®Œå…¨åŒ¹é…
                            if (lowerTitle === lowerQuery || lowerTitle === lowerNormalizedQuery) score += 200;
                            
                            // å…³é”®è¯åŒ¹é…åŠ åˆ†
                            keywords.forEach(kw => {
                                const lowerKw = kw.toLowerCase();
                                if (lowerTitle.includes(lowerKw)) score += 30;
                                if (lowerContent.includes(lowerKw)) score += 10;
                            });
                            
                            // å¤šå…³é”®è¯åŒæ—¶å‡ºç°åŠ åˆ†
                            let matchedKeywords = 0;
                            keywords.forEach(kw => {
                                if (lowerSearchText.includes(kw.toLowerCase())) {
                                    matchedKeywords++;
                                }
                            });
                            if (matchedKeywords > 1) {
                                score += matchedKeywords * 15;
                            }

                            if (results.has(row.id)) {
                                results.get(row.id).score += score;
                            } else {
                                results.set(row.id, { data: Object.values(row), score: score });
                            }
                        }
                        stmt.free();
                        
                        const sortedResults = Array.from(results.values())
                            .sort((a, b) => b.score - a.score)
                            .slice(0, 50)
                            .map(item => item.data);

                        handleQueryResults(sortedResults);
                    } catch (error) {
                        console.error('Error: ' + error.message);
                        search_info.textContent = 'æœç´¢å‡ºé”™ï¼Œè¯·é‡è¯•';
                    }
                }, 300);
                function handleQueryResults(datas) {
                    if (datas.length === 0) {
                        search_info.textContent = 'æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„ç»“æœ';
                        resultList.innerHTML = '';
                        return;
                    } else {
                        search_info.textContent = `${datas.length} ä¸ªç¬¦åˆæ¡ä»¶çš„ç»“æœ`;
                    }
                    var new_datas = {};
                    var global_content_set = new Set(); // å…¨å±€å»é‡é›†åˆ

                    datas.forEach(value => {
                        const [id, url, name, title, link, body, raw_content] = value;
                        const pageUrl = url.endsWith('/') ? url : url + '/';
                        
                        if (!new_datas[pageUrl]) {
                            new_datas[pageUrl] = { url: pageUrl, name, matches: [] };
                        }

                        // æ”¹è¿›çš„å»é‡é€»è¾‘ï¼šä½¿ç”¨æ›´ç²¾ç¡®çš„æ ‡è¯†ç¬¦
                        const normalizedTitle = title.trim().toLowerCase();
                        const normalizedContent = (raw_content || '').trim().toLowerCase();
                        
                        // åˆ›å»ºæ›´ç²¾ç¡®çš„å†…å®¹æŒ‡çº¹
                        const contentFingerprint = `${pageUrl}|${normalizedTitle}|${normalizedContent.substring(0, 200)}`;
                        
                        // æ£€æŸ¥æ˜¯å¦ä¸ºé¡µé¢ä¸»æ ‡é¢˜ä¸é¡µé¢åç§°ç›¸åŒçš„æƒ…å†µ
                        const isPageMainTitle = normalizedTitle === name.trim().toLowerCase() && link === '';
                        
                        // å¦‚æœæ˜¯é¡µé¢ä¸»æ ‡é¢˜ä¸”å·²ç»æœ‰å…¶ä»–åŒ¹é…é¡¹ï¼Œåˆ™è·³è¿‡
                        if (isPageMainTitle && new_datas[pageUrl].matches.length > 0) {
                            return;
                        }
                        
                        // å¦‚æœä¸æ˜¯é‡å¤å†…å®¹ï¼Œåˆ™æ·»åŠ 
                        if (!global_content_set.has(contentFingerprint)) {
                            new_datas[pageUrl].matches.push({ title, link, body, raw_content });
                            global_content_set.add(contentFingerprint);
                        }
                    });

                    // æ¸…ç†ç©ºçš„é¡µé¢æ¡ç›®
                    Object.keys(new_datas).forEach(pageUrl => {
                        if (new_datas[pageUrl].matches.length === 0) {
                            delete new_datas[pageUrl];
                        }
                    });

                    resultList.innerHTML = '';
                    const resultItems = Object.values(new_datas).map(data => `
                        <li class="md-search-result__item" style="border: 2px solid #bababa; margin: 10px; border-radius: 8px;">
                            <div class="md-search-result__link search-result-main" style="border-bottom:1px solid #bababa; cursor: pointer; text-decoration: none;" data-url="${data.url}" data-query="${escapeHtml(currentSearchQuery)}">
                                <article class="md-search-result__article md-typeset">
                                    <div class="md-search-result__icon md-icon"></div>
                                    <h1>${highlightKeywords(data.name, currentSearchQuery)}</h1>
                                </article>
                            </div>
                            ${data.matches.map(match => `
                                <div class="md-search-result__link search-result-item" style="cursor: pointer; text-decoration: none;" data-url="${data.url}${match.link}" data-query="${escapeHtml(currentSearchQuery)}">
                                    <article class="md-search-result__article md-typeset">
                                        <h2>${highlightKeywords(match.title, currentSearchQuery)}</h2>
                                        <div class="search-content-preview">
                                            ${truncateAndHighlight(match.body, match.raw_content, 200, currentSearchQuery)}
                                        </div>
                                    </article>
                                </div>
                            `).join('')}
                        </li>
                    `).join('');
                    resultList.innerHTML = resultItems;
                    
                    // æ·»åŠ ç‚¹å‡»äº‹ä»¶å¤„ç†
                    const resultLinks = resultList.querySelectorAll('.search-result-main, .search-result-item');
                    resultLinks.forEach(link => {
                        link.addEventListener('click', (e) => {
                            e.preventDefault();
                            e.stopPropagation();
                            
                            const targetUrl = link.getAttribute('data-url');
                            const query = link.getAttribute('data-query');
                            
                            if (targetUrl && query) {
                                // å…³é—­æœç´¢æ¡†
                                const toggle = document.querySelector('input[data-md-toggle="search"]');
                                if (toggle) {
                                    toggle.checked = false;
                                }
                                
                                const url = new URL(targetUrl, window.location.origin);
                                url.searchParams.set('highlight', query);
                                window.location.href = url.toString();
                            }
                        });
                    });
                }
            })
        })
    </script>
    """
    html += script_code
    return html

def on_post_build(config):
    """æ„å»ºåé’©å­å‡½æ•°"""
    # æœç´¢åŠŸèƒ½å¼€å…³æ£€æŸ¥
    if not ENABLE_SEARCH:
        return  # é™é»˜è¿”å›ï¼Œä¸é‡å¤æ‰“å°ç¦ç”¨ä¿¡æ¯
    
    global MKDOCS_DOCS_PATH, MKDOCS_SITE_PATH, SQLITE_FILE_PATH
    
    # æ£€æµ‹å¼€å‘æ¨¡å¼
    is_dev_mode = getattr(config, 'dev_addr', None) is not None
    debug_print(f"å¼€å‘æ¨¡å¼: {is_dev_mode}")
    
    if not MKDOCS_SITE_PATH:
        MKDOCS_SITE_PATH = config['site_dir']
    if not SQLITE_FILE_PATH:
        SQLITE_FILE_PATH = os.path.join(MKDOCS_SITE_PATH, "search", "database.sqlite")
    
    # å¼€å‘æ¨¡å¼ä¼˜åŒ–ç­–ç•¥
    if is_dev_mode and DEV_MODE_SKIP_REBUILD:
        if os.path.exists(SQLITE_FILE_PATH):
            file_size = os.path.getsize(SQLITE_FILE_PATH)
            debug_print(f"æ•°æ®åº“æ–‡ä»¶å¤§å°: {file_size} bytes")
            
            if file_size > 1024:  # å¤§äº1KBè¯´æ˜æœ‰å†…å®¹
                print("âš¡ å¼€å‘æ¨¡å¼: ä½¿ç”¨ç¼“å­˜æ•°æ®åº“")
                _copy_sqljs_files()
                return
            else:
                print("ğŸ”„ æ•°æ®åº“å¼‚å¸¸ï¼Œé‡æ–°æ„å»º...")
        else:
            print("ğŸ“¦ é¦–æ¬¡æ„å»ºæœç´¢æ•°æ®åº“...")
        
        # æ‰§è¡Œæ„å»º
        docs = sqlite_index_all_html_files(MKDOCS_SITE_PATH)
        sqlite_create_db_and_insert_data(SQLITE_FILE_PATH, docs)
    
    elif not is_dev_mode:
        # ç”Ÿäº§æ¨¡å¼ä½¿ç”¨å¢é‡ç´¢å¼•
        if not os.path.exists(SQLITE_FILE_PATH):
            print("ğŸ“¦ é¦–æ¬¡æ„å»ºæœç´¢æ•°æ®åº“...")
            docs = sqlite_index_all_html_files(MKDOCS_SITE_PATH)
            sqlite_create_db_and_insert_data(SQLITE_FILE_PATH, docs)
        else:
            changed_files, total_files = get_changed_files(MKDOCS_SITE_PATH)
            if changed_files:
                print(f"ğŸ“Š æ£€æµ‹åˆ° {len(changed_files)}/{total_files} ä¸ªæ–‡ä»¶å˜æ›´")
                sqlite_index_changed_files(changed_files, SQLITE_FILE_PATH)
            else:
                print("ğŸ“„ æ— æ–‡ä»¶å˜æ›´")
    
    else:
        # å¼€å‘æ¨¡å¼ä½†ä¸è·³è¿‡é‡å»º
        print("ğŸ”„ å¼€å‘æ¨¡å¼: å®Œæ•´é‡å»º...")
        docs = sqlite_index_all_html_files(MKDOCS_SITE_PATH)
        sqlite_create_db_and_insert_data(SQLITE_FILE_PATH, docs)
    
    # å¤åˆ¶SQL.jsæ–‡ä»¶
    _copy_sqljs_files()
    
    print("ğŸ‰ æœç´¢åŠŸèƒ½æ„å»ºå®Œæˆ")

def _copy_sqljs_files():
    """å¤åˆ¶SQL.jsæ–‡ä»¶çš„ç‹¬ç«‹å‡½æ•°"""
    if not MKDOCS_SITE_PATH:
        logger.error("MKDOCS_SITE_PATH is not set")
        return
    search_dir = os.path.join(MKDOCS_SITE_PATH, 'search')
    sql_wasm_js = os.path.join(search_dir, 'sql-wasm.js')
    
    if not os.path.exists(sql_wasm_js):
        if not os.path.exists(search_dir):
            os.makedirs(search_dir)
        
        current_dir = os.path.dirname(os.path.abspath(__file__))
        latest_folder = max(
            (folder for folder in os.listdir(current_dir)
            if folder.startswith('sqljs-wasm') and os.path.isdir(os.path.join(current_dir, folder))),
            key=lambda folder: os.path.getmtime(os.path.join(current_dir, folder)),
            default=None
        );
        
        if latest_folder:
            source_js_file = os.path.join(current_dir, latest_folder, 'sql-wasm.js');
            source_wasm_file = os.path.join(current_dir, latest_folder, 'sql-wasm.wasm');
            
            shutil.copy(source_js_file, os.path.join(search_dir, 'sql-wasm.js'));
            shutil.copy(source_wasm_file, os.path.join(search_dir, 'sql-wasm.wasm'));
            
            debug_print("SQL.js åº“æ–‡ä»¶å¤åˆ¶å®Œæˆ")
        else:
            print("âŒ æœªæ‰¾åˆ° SQL.js åº“æ–‡ä»¶")
---
title: Prompt 工程入门：提示词技巧与实战
tags:
  - AI
  - Prompt
---

# Prompt 工程入门：提示词技巧与实战

> Prompt 工程关注如何设计、优化与 LLM 的输入（提示词），以更稳定、高效地得到想要的输出。本文介绍常用技巧和实战要点，适用于 ChatGPT、Claude、DeepSeek、Kimi 等大模型。**表述与示例符合 2025–2026 年主流实践与研究共识。**

**适用读者**：已使用过任意一款大模型对话产品，希望系统提升「问得准、拿得稳」的能力，减少无效输出与反复修改。

## 什么是 Prompt 工程

**Prompt（提示词）** 是你发给大语言模型（LLM）的指令与上下文；**Prompt 工程** 则是系统性地设计、迭代和优化这些输入，以便：

- 更准确理解你的意图  
- 减少无关、错误或格式不对的输出  
- 在复杂任务上表现更稳定  

好的提示词通常包含：**角色/背景**、**任务说明**、**约束与格式**，必要时加上**示例**。

**Zero-Shot** 指不提供示例、仅靠自然语言描述任务；**Few-Shot** 指在提示中给出少量输入-输出示例，让模型对齐格式与风格。复杂或格式要求高的任务，Few-Shot 往往更稳定。

---

## 核心技巧

### 1. 角色设定（Role）

在开头明确「你是谁、你的专业领域」，能显著提高回答的专业度和风格一致性。

**弱示例：**  
「介绍一下减脂。」  

**强示例：**  
「你是一名有 10 年经验的健身与营养教练，擅长科学减脂。请用通俗语言介绍减脂的基本原理和 3 条可执行建议。」

---

### 2. 链式思考（Chain of Thought, CoT）

让模型**先推理、再给结论**，在数学、推理、规划类任务上效果更好。研究与实践表明，显式要求「分步」能显著提升逻辑与推理类表现。

- **零样本 CoT**：在句末直接加英文 **"Let's think step by step"** 或中文「请一步步思考」，无需给示例即可提升推理表现。
- **带示例的 CoT**：在提示中写清步骤与结论的示例，例如：
  - 「请一步步分析，最后给出结论。」
  - 「先列出可能原因，再逐条排除，最后给出最可能的原因。」
  - 「请分步推导，每一步写出依据。」

**适用**：解题、诊断、对比、做决策等需要「过程」的多步推理任务。**注意**：在纯知识问答或简单分类任务上，CoT 有时会「想太多」导致多余推理或错误，可按任务类型选用；不同模型对提示风格偏好不同（如 Claude 倾向简洁聚焦，GPT 系列对更详细的指令往往表现更好），可针对主力模型微调。

---

### 3. 明确输出格式与结构

说清楚你要的**形式**，减少无效输出和二次整理：

- 「请用 Markdown 列表，每条不超过一句话。」  
- 「按以下结构回答：1) 定义 2) 适用场景 3) 注意事项。」  
- 「输出为 JSON：{"步骤": [], "预计时间": ""}。」

---

### 4. 少样本示例（Few-Shot）

在提示里给 1～3 个「输入→输出」示例，让模型对齐你的风格和格式。

**示例：**  
「把下面用户意图改成简洁的产品需求句。  
例1：用户说「我想能快速找到上个月的订单」→ 需求：支持按月份筛选订单。  
例2：用户说「付款后最好有个提醒」→ 需求：付款成功后发送通知。  
现在请改：用户说「……」」

---

### 5. 约束与边界

明确**不要什么**、**范围是什么**，能减少跑题和幻觉：

- 「只基于下面这段文字回答，不要引入外部知识。」  
- 「不要编造数据，没有的信息请直接说不知道。」  
- 「回答控制在 200 字以内，只列要点。」

---

## 实用结构模板

可以按「角色 + 任务 + 格式 + 约束」组织一段提示词：

```
你是一个 [角色/身份]，擅长 [领域]。

请完成以下任务：[具体任务描述]。

要求：
- [约束1，如：只用中文]
- [约束2，如：不编造]
- 输出格式：[结构或示例]

当前输入/上下文：
[你提供的材料、问题或数据]
```

根据任务替换括号内容即可。

---

## 常见问题与改进

| 现象 | 可能原因 | 改进方向 |
|------|----------|----------|
| 回答太泛、不贴题 | 任务描述模糊 | 加角色、加具体场景、加「不要……」 |
| 格式乱、不好用 | 没规定输出形式 | 明确列表/表格/JSON/分节 |
| 经常瞎编 | 模型用了「脑补」 | 强调「仅根据上文」「不知道就说不知道」、或配合 RAG 给原文 |
| 过程跳步、不推理 | 需要推理但没引导 | 加 CoT：「请先……再……最后……」 |
| 风格不对 | 没给参考 | 加 1～2 个 Few-Shot 示例 |
| 输出被截断、不完整 | 生成长度超限或未要求「继续」 | 明确「若超过 N 字请分条续写」、或拆成多轮短提示 |

---

## 和 Agent、RAG、Skill 的关系

- **Prompt**：单轮或短对话里「怎么问、怎么约束」——是基础。  
- **Agent**：多步任务时，每步都可以用更好的提示词驱动模型做规划、选工具。  
- **RAG**：先检索再生成时，把「检索到的内容」作为提示词的一部分，能大幅减少幻觉。  
- **Skill**：在 Cursor/Codex 等里，Skill 里写的正是「在什么情况下、按什么步骤、用何种提示逻辑」——可把常用提示固化进 Skill。

---

## 小结

- **角色 + 任务 + 格式 + 约束** 是提示词的基本骨架。  
- **链式思考（CoT）** 适合需要推理过程的任务；**Few-Shot** 适合要固定风格或格式的任务。  
- 效果不好时，优先检查：是否说清了角色、是否限制了范围和格式、是否给了示例或推理指引。  
- 把常用提示整理成模板或写进 Skill，可以反复复用、持续迭代。

**进阶方向**：提示链（Prompt Chaining，多轮提示串联）、思维树（Tree of Thought，多分支推理）、自洽性 CoT（Self-Consistency：生成多条推理路径取共识）、与 RAG 结合做「检索后再生成」等，可结合 [RAG 技术](rag.md)、[Skill 使用介绍](skill.md) 在具体产品中实践。

**延伸阅读**：[Prompt Engineering Guide](https://www.promptingguide.ai/zh)（中文）、[AI Agent 入门](agent.md)（多步任务中的提示设计）、[RAG 技术](rag.md)（检索增强与上下文构造）。

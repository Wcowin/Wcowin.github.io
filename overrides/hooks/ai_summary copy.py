from dotenv import load_dotenv
load_dotenv()  # è‡ªåŠ¨åŠ è½½ .env æ–‡ä»¶

import re
import json
import hashlib
import requests
from pathlib import Path
from datetime import datetime
import os
import shutil

class AISummaryGenerator:
    def __init__(self):
        """
        AIæ‘˜è¦ç”Ÿæˆå™¨åˆå§‹åŒ–
        
        ä¸»è¦åŠŸèƒ½ï¼š
        1. é…ç½®ç¼“å­˜ç³»ç»Ÿ
        2. æ£€æµ‹è¿è¡Œç¯å¢ƒï¼ˆCI/æœ¬åœ°ï¼‰
        3. åˆå§‹åŒ–AIæœåŠ¡é…ç½®
        4. è®¾ç½®æ–‡ä»¶å¤¹å’Œè¯­è¨€é…ç½®
        """
        # ğŸ—‚ï¸ ç»Ÿä¸€ç¼“å­˜è·¯å¾„ - é¡¹ç›®æ ¹ç›®å½•
        # ä¼˜åŠ¿ï¼šCIå’Œæœ¬åœ°ç¯å¢ƒä½¿ç”¨åŒä¸€è·¯å¾„ï¼Œä¾¿äºç¼“å­˜å…±äº«å’Œç®¡ç†
        self.cache_dir = Path(".ai_cache")
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        # ğŸ”§ ç¼“å­˜é…ç½® - ç®€åŒ–é…ç½®é€»è¾‘
        # å°†æ‰€æœ‰ç¼“å­˜ç›¸å…³é…ç½®é›†ä¸­ç®¡ç†ï¼Œä¾¿äºç†è§£å’Œä¿®æ”¹
        self.cache_config = {
            # æ˜¯å¦å¯ç”¨ç¼“å­˜åŠŸèƒ½ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
            'enabled': os.getenv('AI_SUMMARY_CACHE_ENABLED', 'true').lower() == 'true',
            
            # ç¼“å­˜è¿‡æœŸå¤©æ•°ï¼ˆé»˜è®¤7å¤©ï¼‰
            'expire_days': int(os.getenv('AI_SUMMARY_CACHE_EXPIRE_DAYS', '7')),
            
            # æ˜¯å¦è‡ªåŠ¨æ¸…ç†è¿‡æœŸç¼“å­˜ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
            'auto_clean': os.getenv('AI_SUMMARY_CACHE_AUTO_CLEAN', 'true').lower() == 'true'
        }
        
        # ğŸš€ ç¯å¢ƒé…ç½® - æ¸…æ™°çš„ç¯å¢ƒæ§åˆ¶
        # åˆ†ç¦»ç¯å¢ƒæ£€æµ‹å’Œé…ç½®ï¼Œè®©é€»è¾‘æ›´æ¸…æ™°
        self.env_config = {
            # å½“å‰æ˜¯å¦ä¸ºCIç¯å¢ƒ
            'is_ci': self._detect_ci_environment(),
            
            # CIç¯å¢ƒæ˜¯å¦å¯ç”¨AIæ‘˜è¦ï¼ˆä¸ç”¨ç®¡ï¼Œåªåœ¨ci.ymlä¸­è®¾ç½®æœ‰æ•ˆã€‚é»˜è®¤å¯ç”¨ï¼‰
            'ci_enabled': os.getenv('AI_SUMMARY_CI_ENABLED', 'true').lower() == 'true',
            
            # æœ¬åœ°ç¯å¢ƒæ˜¯å¦å¯ç”¨AIæ‘˜è¦ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
            'local_enabled': os.getenv('AI_SUMMARY_LOCAL_ENABLED', 'false').lower() == 'true',
            
            # CIç¯å¢ƒæ˜¯å¦ä»…ä½¿ç”¨ç¼“å­˜ï¼ˆä¸ç”¨ç®¡ï¼Œåªåœ¨ci.ymlä¸­è®¾ç½®æœ‰æ•ˆã€‚é»˜è®¤å…³é—­ï¼Œå³å…è®¸ç”Ÿæˆæ–°æ‘˜è¦ï¼‰
            'ci_cache_only': os.getenv('AI_SUMMARY_CI_ONLY_CACHE', 'false').lower() == 'true',
            
            # CIç¯å¢ƒæ˜¯å¦å¯ç”¨å¤‡ç”¨æ‘˜è¦ï¼ˆä¸ç”¨ç®¡ï¼Œåªåœ¨ci.ymlä¸­è®¾ç½®æœ‰æ•ˆã€‚é»˜è®¤å¯ç”¨ï¼‰
            'ci_fallback': os.getenv('AI_SUMMARY_CI_FALLBACK', 'true').lower() == 'true'
        }
        
        # æœåŠ¡é…ç½®æ–‡ä»¶ - ç”¨äºè·Ÿè¸ªAIæœåŠ¡å’Œè¯­è¨€è®¾ç½®å˜åŒ–
        self.service_config_file = self.cache_dir / "service_config.json"
        
        # ğŸ¤– å¤šAIæœåŠ¡é…ç½®
        self.ai_services = {
            'deepseek': {
                'url': 'https://api.deepseek.com/v1/chat/completions',
                'model': 'deepseek-chat',
                'api_key': os.getenv('DEEPSEEK_API_KEY', ),
                'max_tokens': 150,
                'temperature': 0.3
            },
            'openai': {
                'url': 'https://api.chatanywhere.tech/v1/chat/completions',
                'model': 'gpt-3.5-turbo',  # æˆ– 'gpt-4', 'gpt-4-turbo'
                'api_key': os.getenv('OPENAI_API_KEY', ),
                'max_tokens': 200,
                'temperature': 0.3
            },
            'gemini': {
                'url': 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent',
                'model': 'gemini-pro',
                'api_key': os.getenv('GOOGLE_API_KEY', ''),
                'max_tokens': 150,
                'temperature': 0.3
            }
        }
        
        # é»˜è®¤ä½¿ç”¨çš„AIæœåŠ¡
        self.default_service = 'openai'
        
        # æœåŠ¡ä¼˜å…ˆçº§ï¼ˆæŒ‰é¡ºåºå°è¯•ï¼‰
        self.service_fallback_order = ['openai', 'deepseek', 'claude', 'gemini']
        
        # ğŸ“‚ å¯è‡ªå®šä¹‰çš„æ–‡ä»¶å¤¹é…ç½®
        self.enabled_folders = [
            'blog/',      # blogæ–‡ä»¶å¤¹
            'develop/',   # developæ–‡ä»¶å¤¹
            # 'posts/',     # postsæ–‡ä»¶å¤¹
            'trip/',     # tripæ–‡ä»¶å¤¹
            # 'about/',     # aboutæ–‡ä»¶å¤¹
        ]
        
        # ğŸ“‹ æ’é™¤çš„æ–‡ä»¶å’Œæ–‡ä»¶å¤¹
        self.exclude_patterns = [
            'waline.md', 'link.md', '404.md', 'tag.md', 'tags.md',
            '/about/', '/search/', '/sitemap', '/admin/',
            'index.md',  # æ ¹ç›®å½•index.md
        ]
        
        # ğŸ“‹ æ’é™¤çš„ç‰¹å®šæ–‡ä»¶
        self.exclude_files = [
            'blog/index.md',
            'blog/indexblog.md',
            'docs/index.md',
            'develop/index.md',
        ]
        
        # ğŸŒ è¯­è¨€é…ç½®/Language Configuration
        self.summary_language = 'zh'  # é»˜è®¤è‹±æ–‡ï¼Œå¯é€‰ 'zh'ã€'en'ã€'both'
        
        # åˆå§‹åŒ–æ£€æŸ¥
        self._initialize()
    
    def _initialize(self):
        """
        ç³»ç»Ÿåˆå§‹åŒ–æµç¨‹
        
        æ­¥éª¤ï¼š
        1. æ£€æŸ¥å¹¶è®°å½•å½“å‰è¿è¡Œç¯å¢ƒ
        2. å¦‚æœç¼“å­˜å¯ç”¨ï¼Œæ£€æŸ¥æœåŠ¡é…ç½®å˜æ›´
        3. å¦‚æœè®¾ç½®äº†è‡ªåŠ¨æ¸…ç†ï¼Œæ¸…ç†è¿‡æœŸç¼“å­˜
        """
        # ç¯å¢ƒæ£€æŸ¥ - ç¡®å®šå½“å‰ç¯å¢ƒå¹¶è®¾ç½®è¿è¡ŒçŠ¶æ€
        self._check_and_log_environment()
        
        # ç¼“å­˜ç›¸å…³æ£€æŸ¥ - åªåœ¨ç¼“å­˜å¯ç”¨æ—¶æ‰§è¡Œ
        if self.cache_config['enabled']:
            # æ£€æŸ¥AIæœåŠ¡æˆ–è¯­è¨€é…ç½®æ˜¯å¦å˜æ›´ï¼Œå¦‚æœ‰å˜æ›´åˆ™æ¸…ç†ç¼“å­˜
            self._check_service_change()
            
            # å¦‚æœå¯ç”¨äº†è‡ªåŠ¨æ¸…ç†ï¼Œæ¸…ç†è¿‡æœŸçš„ç¼“å­˜æ–‡ä»¶
            if self.cache_config['auto_clean']:
                self._clean_expired_cache()
        else:
            print("ğŸš« ç¼“å­˜åŠŸèƒ½å·²ç¦ç”¨")
    
    def _detect_ci_environment(self):
        """
        æ£€æµ‹å½“å‰æ˜¯å¦åœ¨CIç¯å¢ƒä¸­è¿è¡Œ
        
        é€šè¿‡æ£€æŸ¥å¸¸è§çš„CIç¯å¢ƒå˜é‡æ¥åˆ¤æ–­ï¼š
        - CI/CONTINUOUS_INTEGRATION: é€šç”¨CIæ ‡è¯†
        - GITHUB_ACTIONS: GitHub Actions
        - GITLAB_CI: GitLab CI
        - å…¶ä»–ä¸»æµCI/CDå¹³å°çš„æ ‡è¯†å˜é‡
        
        Returns:
            bool: Trueè¡¨ç¤ºåœ¨CIç¯å¢ƒä¸­ï¼ŒFalseè¡¨ç¤ºåœ¨æœ¬åœ°ç¯å¢ƒä¸­
        """
        ci_indicators = [
            'CI', 'CONTINUOUS_INTEGRATION', 'GITHUB_ACTIONS', 'GITLAB_CI',
            'JENKINS_URL', 'TRAVIS', 'CIRCLECI', 'AZURE_HTTP_USER_AGENT',
            'TEAMCITY_VERSION', 'BUILDKITE', 'CODEBUILD_BUILD_ID',
            'NETLIFY', 'VERCEL', 'CF_PAGES'
        ]
        return any(os.getenv(indicator) for indicator in ci_indicators)
    
    def _check_and_log_environment(self):
        """
        æ£€æŸ¥å½“å‰ç¯å¢ƒé…ç½®å¹¶è®°å½•æ—¥å¿—
        
        æ ¹æ®ç¯å¢ƒç±»å‹ï¼ˆCI/æœ¬åœ°ï¼‰å’Œç›¸åº”çš„é…ç½®é¡¹ï¼Œå†³å®šï¼š
        1. æ˜¯å¦å¯ç”¨AIæ‘˜è¦åŠŸèƒ½
        2. å¦‚æœæ˜¯CIç¯å¢ƒï¼Œæ˜¯å¦ä½¿ç”¨ä»…ç¼“å­˜æ¨¡å¼
        3. è®¾ç½®å†…éƒ¨çŠ¶æ€å˜é‡ self._should_run
        """
        if self.env_config['is_ci']:
            # CIç¯å¢ƒå¤„ç†é€»è¾‘
            ci_name = self._get_ci_name()
            
            if self.env_config['ci_enabled']:
                # CIç¯å¢ƒå¯ç”¨äº†AIæ‘˜è¦
                if self.env_config['ci_cache_only']:
                    # ä»…ä½¿ç”¨ç¼“å­˜æ¨¡å¼ - ä¸ç”Ÿæˆæ–°æ‘˜è¦ï¼Œåªä½¿ç”¨å·²æœ‰ç¼“å­˜
                    print(f"ğŸš€ CIç¯å¢ƒ ({ci_name}) - ä»…ä½¿ç”¨ç¼“å­˜æ¨¡å¼")
                else:
                    # å®Œæ•´æ¨¡å¼ - å¯ä»¥ç”Ÿæˆæ–°æ‘˜è¦
                    print(f"ğŸš€ CIç¯å¢ƒ ({ci_name}) - AIæ‘˜è¦å·²å¯ç”¨")
                self._should_run = True
            else:
                # CIç¯å¢ƒç¦ç”¨äº†AIæ‘˜è¦
                print(f"ğŸš« CIç¯å¢ƒ ({ci_name}) - AIæ‘˜è¦å·²ç¦ç”¨")
                self._should_run = False
        else:
            # æœ¬åœ°ç¯å¢ƒå¤„ç†é€»è¾‘
            if self.env_config['local_enabled']:
                print("ğŸ’» æœ¬åœ°ç¯å¢ƒ - AIæ‘˜è¦å·²å¯ç”¨")
                self._should_run = True
            else:
                print("ğŸš« æœ¬åœ°ç¯å¢ƒ - AIæ‘˜è¦å·²ç¦ç”¨")
                self._should_run = False
    
    def _check_service_change(self):
        """
        æ£€æŸ¥AIæœåŠ¡é…ç½®å˜æ›´
        
        æ¯”è¾ƒå½“å‰é…ç½®ä¸ä¸Šæ¬¡ä¿å­˜çš„é…ç½®ï¼š
        1. AIæœåŠ¡æ˜¯å¦å˜æ›´ï¼ˆå¦‚ä»OpenAIåˆ‡æ¢åˆ°DeepSeekï¼‰
        2. è¯­è¨€è®¾ç½®æ˜¯å¦å˜æ›´ï¼ˆå¦‚ä»ä¸­æ–‡åˆ‡æ¢åˆ°è‹±æ–‡ï¼‰
        3. ç‰ˆæœ¬æ˜¯å¦æ›´æ–°
        
        å¦‚æœæœ‰ä»»ä½•å˜æ›´ï¼Œè‡ªåŠ¨æ¸…ç†ç›¸å…³ç¼“å­˜ä»¥é¿å…æ··ç”¨
        """
        # å½“å‰é…ç½®å¿«ç…§
        current_config = {
            'default_service': self.default_service,
            'summary_language': self.summary_language,
            'version': '1.3.0'  # ç‰ˆæœ¬å·ç”¨äºç‰ˆæœ¬å‡çº§æ—¶çš„ç¼“å­˜æ¸…ç†
        }
        
        config_changed = False
        
        # è¯»å–ä¹‹å‰ä¿å­˜çš„é…ç½®
        if self.service_config_file.exists():
            try:
                with open(self.service_config_file, 'r', encoding='utf-8') as f:
                    previous_config = json.load(f)
                
                # é€é¡¹æ£€æŸ¥å…³é”®é…ç½®æ˜¯å¦å˜æ›´
                if (previous_config.get('default_service') != current_config['default_service'] or
                    previous_config.get('summary_language') != current_config['summary_language'] or
                    previous_config.get('version') != current_config['version']):
                    
                    # è®°å½•å˜æ›´è¯¦æƒ…
                    old_service = previous_config.get('default_service', 'unknown')
                    old_lang = previous_config.get('summary_language', 'zh')
                    
                    print(f"ğŸ”„ æ£€æµ‹åˆ°é…ç½®å˜æ›´:")
                    if old_service != current_config['default_service']:
                        print(f"   AIæœåŠ¡: {old_service} â†’ {current_config['default_service']}")
                    if old_lang != current_config['summary_language']:
                        print(f"   è¯­è¨€è®¾ç½®: {old_lang} â†’ {current_config['summary_language']}")
                    
                    config_changed = True
                
            except Exception as e:
                # é…ç½®æ–‡ä»¶æŸåæˆ–è¯»å–å¤±è´¥ï¼Œè§†ä¸ºé…ç½®å˜æ›´
                print(f"âš ï¸ è¯»å–æœåŠ¡é…ç½®å¤±è´¥: {e}")
                config_changed = True
        else:
            # é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œé¦–æ¬¡è¿è¡Œ
            config_changed = True
        
        # å¦‚æœé…ç½®å˜æ›´ï¼Œæ¸…ç†æ‰€æœ‰ç¼“å­˜
        if config_changed:
            self._clear_all_cache()
        
        # ä¿å­˜å½“å‰é…ç½®ä¾›ä¸‹æ¬¡æ¯”è¾ƒ
        self._save_service_config(current_config)
    
    def _clear_all_cache(self):
        """
        æ¸…ç†æ‰€æœ‰æ‘˜è¦ç¼“å­˜æ–‡ä»¶
        
        ä¿ç•™é…ç½®æ–‡ä»¶ï¼Œåªæ¸…ç†æ‘˜è¦ç¼“å­˜æ–‡ä»¶ï¼š
        - ä¿ç•™ï¼šservice_config.jsonï¼ˆæœåŠ¡é…ç½®ï¼‰
        - æ¸…ç†ï¼šå…¶ä»–æ‰€æœ‰ .json ç¼“å­˜æ–‡ä»¶
        """
        try:
            cache_files = list(self.cache_dir.glob("*.json"))
            config_files = ['service_config.json']  # éœ€è¦ä¿ç•™çš„é…ç½®æ–‡ä»¶
            
            cleared_count = 0
            for cache_file in cache_files:
                if cache_file.name not in config_files:
                    cache_file.unlink()
                    cleared_count += 1
            
            if cleared_count > 0:
                print(f"ğŸ§¹ å·²æ¸…ç† {cleared_count} ä¸ªç¼“å­˜æ–‡ä»¶")
            
        except Exception as e:
            print(f"âŒ æ¸…ç†ç¼“å­˜å¤±è´¥: {e}")
    
    def _clean_expired_cache(self):
        """
        æ¸…ç†è¿‡æœŸçš„ç¼“å­˜æ–‡ä»¶
        
        æ£€æŸ¥æ¯ä¸ªç¼“å­˜æ–‡ä»¶çš„æ—¶é—´æˆ³ï¼š
        1. å¦‚æœè¶…è¿‡è®¾å®šçš„è¿‡æœŸå¤©æ•°ï¼Œåˆ é™¤æ–‡ä»¶
        2. å¦‚æœæ–‡ä»¶æŸåæ— æ³•è¯»å–ï¼Œä¹Ÿåˆ é™¤
        3. ä¿ç•™é…ç½®æ–‡ä»¶ä¸åšæ¸…ç†
        """
        if not self.cache_config['enabled']:
            return
        
        try:
            current_time = datetime.now()
            expired_count = 0
            
            # éå†æ‰€æœ‰ç¼“å­˜æ–‡ä»¶
            for cache_file in self.cache_dir.glob("*.json"):
                # è·³è¿‡é…ç½®æ–‡ä»¶
                if cache_file.name == "service_config.json":
                    continue
                
                try:
                    # è¯»å–ç¼“å­˜æ–‡ä»¶çš„æ—¶é—´æˆ³
                    with open(cache_file, 'r', encoding='utf-8') as f:
                        cache_data = json.load(f)
                    
                    # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
                    cache_time = datetime.fromisoformat(cache_data.get('timestamp', '1970-01-01'))
                    if (current_time - cache_time).days >= self.cache_config['expire_days']:
                        cache_file.unlink()
                        expired_count += 1
                        
                except Exception:
                    # å¦‚æœæ–‡ä»¶æŸåæ— æ³•è¯»å–ï¼Œç›´æ¥åˆ é™¤
                    cache_file.unlink()
                    expired_count += 1
            
            if expired_count > 0:
                print(f"ğŸ§¹ æ¸…ç†äº† {expired_count} ä¸ªè¿‡æœŸç¼“å­˜æ–‡ä»¶")
                
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†è¿‡æœŸç¼“å­˜å¤±è´¥: {e}")
    
    def _save_service_config(self, config):
        """
        ä¿å­˜æœåŠ¡é…ç½®åˆ°æ–‡ä»¶
        
        Args:
            config (dict): åŒ…å«æœåŠ¡å’Œè¯­è¨€é…ç½®çš„å­—å…¸
        """
        try:
            with open(self.service_config_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜æœåŠ¡é…ç½®å¤±è´¥: {e}")
    
    def should_use_cache(self):
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥ä½¿ç”¨ç¼“å­˜
        
        ç®€å•çš„ç¼“å­˜å¼€å…³æ£€æŸ¥ï¼Œä¾¿äºåœ¨ä»£ç ä¸­ç»Ÿä¸€æ§åˆ¶ç¼“å­˜è¡Œä¸º
        
        Returns:
            bool: Trueè¡¨ç¤ºåº”è¯¥ä½¿ç”¨ç¼“å­˜ï¼ŒFalseè¡¨ç¤ºä¸ä½¿ç”¨ç¼“å­˜
        """
        return self.cache_config['enabled']
    
    def should_generate_new_summary(self):
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥ç”Ÿæˆæ–°çš„AIæ‘˜è¦
        
        å†³ç­–é€»è¾‘ï¼š
        1. å¦‚æœç¼“å­˜è¢«ç¦ç”¨ â†’ æ€»æ˜¯ç”Ÿæˆæ–°æ‘˜è¦
        2. å¦‚æœæ˜¯CIç¯å¢ƒä¸”è®¾ç½®ä¸ºä»…ç¼“å­˜æ¨¡å¼ â†’ ä¸ç”Ÿæˆæ–°æ‘˜è¦
        3. å…¶ä»–æƒ…å†µ â†’ å¯ä»¥ç”Ÿæˆæ–°æ‘˜è¦
        
        Returns:
            bool: Trueè¡¨ç¤ºå¯ä»¥ç”Ÿæˆæ–°æ‘˜è¦ï¼ŒFalseè¡¨ç¤ºä¸åº”ç”Ÿæˆ
        """
        # ç¼“å­˜è¢«ç¦ç”¨æ—¶ï¼Œæ€»æ˜¯ç”Ÿæˆæ–°æ‘˜è¦
        if not self.cache_config['enabled']:
            return True
        
        # CIç¯å¢ƒä¸”è®¾ç½®ä¸ºä»…ç¼“å­˜æ¨¡å¼æ—¶ï¼Œä¸ç”Ÿæˆæ–°æ‘˜è¦
        if self.env_config['is_ci'] and self.env_config['ci_cache_only']:
            return False
        
        # é»˜è®¤æƒ…å†µä¸‹å¯ä»¥ç”Ÿæˆæ–°æ‘˜è¦
        return True
    
    def get_cached_summary(self, content_hash):
        """
        è·å–ç¼“å­˜çš„æ‘˜è¦
        
        Args:
            content_hash (str): å†…å®¹çš„MD5å“ˆå¸Œå€¼
            
        Returns:
            dict|None: ç¼“å­˜çš„æ‘˜è¦æ•°æ®ï¼Œå¦‚æœæ²¡æœ‰æœ‰æ•ˆç¼“å­˜åˆ™è¿”å›None
            
        ç¼“å­˜æ–‡ä»¶ç»“æ„ï¼š
        {
            "summary": "æ‘˜è¦å†…å®¹",
            "service": "ä½¿ç”¨çš„AIæœåŠ¡",
            "page_title": "é¡µé¢æ ‡é¢˜",
            "timestamp": "ç”Ÿæˆæ—¶é—´",
            "language": "æ‘˜è¦è¯­è¨€",
            "cache_version": "ç¼“å­˜ç‰ˆæœ¬"
        }
        """
        # å¦‚æœç¼“å­˜è¢«ç¦ç”¨ï¼Œç›´æ¥è¿”å›None
        if not self.should_use_cache():
            return None
        
        cache_file = self.cache_dir / f"{content_hash}.json"
        if not cache_file.exists():
            return None
        
        try:
            # è¯»å–ç¼“å­˜æ–‡ä»¶
            with open(cache_file, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)
            
            # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
            cache_time = datetime.fromisoformat(cache_data.get('timestamp', '1970-01-01'))
            if (datetime.now() - cache_time).days < self.cache_config['expire_days']:
                # ç¼“å­˜æœ‰æ•ˆï¼Œè¿”å›æ•°æ®
                return cache_data
            else:
                # ç¼“å­˜è¿‡æœŸï¼Œåˆ é™¤æ–‡ä»¶
                cache_file.unlink()
                return None
                
        except Exception as e:
            print(f"âš ï¸ è¯»å–ç¼“å­˜å¤±è´¥: {e}")
            # åˆ é™¤æŸåçš„ç¼“å­˜æ–‡ä»¶
            try:
                cache_file.unlink()
            except:
                pass
            return None
    
    def save_summary_cache(self, content_hash, summary_data):
        """
        ä¿å­˜æ‘˜è¦åˆ°ç¼“å­˜
        
        Args:
            content_hash (str): å†…å®¹çš„MD5å“ˆå¸Œå€¼
            summary_data (dict): è¦ä¿å­˜çš„æ‘˜è¦æ•°æ®
            
        ä¿å­˜çš„æ•°æ®ä¼šè‡ªåŠ¨æ·»åŠ ï¼š
        - timestamp: å½“å‰æ—¶é—´æˆ³
        - language: å½“å‰è¯­è¨€è®¾ç½®
        - cache_version: ç¼“å­˜ç‰ˆæœ¬å·
        """
        # å¦‚æœç¼“å­˜è¢«ç¦ç”¨ï¼Œä¸ä¿å­˜
        if not self.should_use_cache():
            return
        
        cache_file = self.cache_dir / f"{content_hash}.json"
        try:
            # æ·»åŠ ç¼“å­˜å…ƒæ•°æ®
            summary_data.update({
                'timestamp': datetime.now().isoformat(),
                'language': self.summary_language,
                'cache_version': '1.3.0'
            })
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(summary_data, f, ensure_ascii=False, indent=2)
                
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")
    
    def configure_ai_service(self, service_name, config=None):
        """
        é…ç½®AIæœåŠ¡
        
        Args:
            service_name: æœåŠ¡åç§° ('deepseek', 'openai', 'azure_openai', 'claude', 'gemini')
            config: æœåŠ¡é…ç½®å­—å…¸
        """
        old_service = self.default_service
        
        if config:
            self.ai_services[service_name] = config
        self.default_service = service_name
        
        # å¦‚æœæœåŠ¡å‘ç”Ÿå˜æ›´ï¼Œè‡ªåŠ¨æ¸…ç†ç¼“å­˜
        if old_service != service_name:
            print(f"ğŸ”„ AIæœåŠ¡å·²åˆ‡æ¢: {old_service} â†’ {service_name}")
            print("ğŸ§¹ è‡ªåŠ¨æ¸…ç†æ‰€æœ‰AIæ‘˜è¦ç¼“å­˜...")
            
            try:
                if self.cache_dir.exists():
                    shutil.rmtree(self.cache_dir)
                    print(f"âœ… å·²åˆ é™¤ç¼“å­˜æ–‡ä»¶å¤¹: {self.cache_dir}")
                
                # é‡æ–°åˆ›å»ºç¼“å­˜ç›®å½•
                self.cache_dir.mkdir(exist_ok=True)
                print("ğŸ“ å·²é‡æ–°åˆ›å»ºç¼“å­˜ç›®å½•")
                
            except Exception as e:
                print(f"âŒ æ¸…ç†ç¼“å­˜å¤±è´¥: {e}")
                # å¦‚æœåˆ é™¤å¤±è´¥ï¼Œå°è¯•æ¸…ç†å•ä¸ªæ–‡ä»¶
                try:
                    self._clear_cache_files()
                except:
                    print("âš ï¸ ç¼“å­˜æ¸…ç†å¤±è´¥ï¼Œæ–°æ‘˜è¦å¯èƒ½ä¼šæ··ç”¨æ—§æœåŠ¡çš„ç¼“å­˜")
        
        # æ›´æ–°æœåŠ¡é…ç½®è®°å½•
        self._check_service_change()
    
    def configure_folders(self, folders=None, exclude_patterns=None, exclude_files=None):
        """é…ç½®å¯ç”¨AIæ‘˜è¦çš„æ–‡ä»¶å¤¹"""
        if folders is not None:
            self.enabled_folders = folders
        if exclude_patterns is not None:
            self.exclude_patterns = exclude_patterns
        if exclude_files is not None:
            self.exclude_files = exclude_files
    
    def get_content_hash(self, content):
        """ç”Ÿæˆå†…å®¹hashç”¨äºç¼“å­˜ï¼ˆåŒ…å«è¯­è¨€è®¾ç½®ï¼‰"""
        content_with_lang = f"{content}_{self.summary_language}"
        return hashlib.md5(content_with_lang.encode('utf-8')).hexdigest()
    
    def clean_content_for_ai(self, markdown):
        """æ¸…ç†å†…å®¹ï¼Œæå–ä¸»è¦æ–‡æœ¬ç”¨äºAIå¤„ç†"""
        content = markdown
        
        # ç§»é™¤YAML front matter
        content = re.sub(r'^---.*?---\s*', '', content, flags=re.DOTALL)
        
        # ç§»é™¤å·²å­˜åœ¨çš„é˜…è¯»ä¿¡æ¯å—å’ŒAIæ‘˜è¦å—
        content = re.sub(r'!!! info "ğŸ“– é˜…è¯»ä¿¡æ¯".*?(?=\n\n|\n#|\Z)', '', content, flags=re.DOTALL)
        content = re.sub(r'!!! info "ğŸ¤– AIæ™ºèƒ½æ‘˜è¦".*?(?=\n\n|\n#|\Z)', '', content, flags=re.DOTALL)
        content = re.sub(r'!!! tip "ğŸ“ è‡ªåŠ¨æ‘˜è¦".*?(?=\n\n|\n#|\Z)', '', content, flags=re.DOTALL)
        
        # ç§»é™¤HTMLæ ‡ç­¾
        content = re.sub(r'<[^>]+>', '', content)
        
        # ç§»é™¤å›¾ç‰‡ï¼Œä¿ç•™altæ–‡æœ¬ä½œä¸ºå†…å®¹æç¤º
        content = re.sub(r'!\[([^\]]*)\]\([^)]+\)', r'[å›¾ç‰‡ï¼š\1]', content)
        
        # ç§»é™¤é“¾æ¥ï¼Œä¿ç•™æ–‡æœ¬
        content = re.sub(r'\[([^\]]+)\]\([^)]+\)', r'\1', content)
        
        # ç§»é™¤ä»£ç å—ï¼Œä½†ä¿ç•™å…³é”®ä¿¡æ¯
        content = re.sub(r'```(\w+)?\n(.*?)\n```', r'[ä»£ç ç¤ºä¾‹]', content, flags=re.DOTALL)
        
        # ç§»é™¤è¡Œå†…ä»£ç 
        content = re.sub(r'`[^`]+`', '[ä»£ç ]', content)
        
        # ç§»é™¤è¡¨æ ¼æ ¼å¼ä½†ä¿ç•™å†…å®¹
        content = re.sub(r'\|[^\n]+\|', '', content)
        content = re.sub(r'^[-|:\s]+$', '', content, flags=re.MULTILINE)
        
        # æ¸…ç†æ ¼å¼ç¬¦å·
        content = re.sub(r'\*\*([^*]+)\*\*', r'\1', content)  # ç²—ä½“
        content = re.sub(r'\*([^*]+)\*', r'\1', content)      # æ–œä½“
        content = re.sub(r'^#+\s*', '', content, flags=re.MULTILINE)  # æ ‡é¢˜ç¬¦å·
        
        # ç§»é™¤å¤šä½™çš„ç©ºè¡Œå’Œç©ºæ ¼
        content = re.sub(r'\n\s*\n', '\n\n', content)
        content = re.sub(r'^[ \t]+', '', content, flags=re.MULTILINE)
        content = content.strip()
        
        return content
    
    def build_headers(self, service_config):
        """æ„å»ºè¯·æ±‚å¤´"""
        headers = {
            'Content-Type': 'application/json'
        }
        
        # æ ¹æ®æœåŠ¡ç±»å‹æ·»åŠ è®¤è¯å¤´
        if 'azure_openai' in service_config.get('url', ''):
            headers['api-key'] = service_config['api_key']
        elif 'anthropic.com' in service_config.get('url', ''):
            headers['x-api-key'] = service_config['api_key']
            headers['anthropic-version'] = '2023-06-01'
        elif 'googleapis.com' in service_config.get('url', ''):
            # Google APIä½¿ç”¨URLå‚æ•°
            pass
        else:
            # OpenAIå’ŒDeepSeekä½¿ç”¨Bearer token
            headers['Authorization'] = f"Bearer {service_config['api_key']}"
        
        # æ·»åŠ é¢å¤–çš„å¤´éƒ¨
        if 'headers_extra' in service_config:
            headers.update(service_config['headers_extra'])
        
        return headers
    
    def build_payload(self, service_name, service_config, content, page_title):
        """æ„å»ºè¯·æ±‚è½½è·"""
        # æ ¹æ®è¯­è¨€è®¾ç½®ç”Ÿæˆä¸åŒçš„prompt
        if self.summary_language == 'en':
            prompt = f"""Please generate a high-quality summary for the following technical article with these requirements:

1. **Length Control**: Strictly limit to 80-120 words
2. **Content Requirements**:
   - Accurately summarize the core themes and key points of the article
   - Highlight technical features, application scenarios, or problems solved
   - Use professional but understandable language
   - Avoid repeating the article title content
3. **Format Requirements**:
   - Return summary content directly without any prefix or suffix
   - Use concise declarative sentences
   - Technical terms are appropriate

Article Title: {page_title}

Article Content:
{content[:2500]}

Please generate summary:"""

        elif self.summary_language == 'both':
            prompt = f"""Please generate a bilingual summary (Chinese and English) for the following technical article with these requirements:

1. **Length Control**: 
   - Chinese: 80-120 characters
   - English: 80-120 words
2. **Content Requirements**:
   - Accurately summarize the core themes and key points
   - Highlight technical features, application scenarios, or problems solved
   - Use professional but understandable language
   - Avoid repeating the article title content
3. **Format Requirements**:
   - First provide Chinese summary
   - Then provide English summary
   - Separate with a blank line
   - No prefixes or additional formatting

Article Title: {page_title}

Article Content:
{content[:2500]}

Please generate bilingual summary:"""

        else:  # é»˜è®¤ä¸­æ–‡
            prompt = f"""è¯·ä¸ºä»¥ä¸‹æŠ€æœ¯æ–‡ç« ç”Ÿæˆä¸€ä¸ªé«˜è´¨é‡çš„æ‘˜è¦ï¼Œè¦æ±‚ï¼š

1. **é•¿åº¦æ§åˆ¶**ï¼šä¸¥æ ¼æ§åˆ¶åœ¨80-120å­—ä»¥å†…
2. **å†…å®¹è¦æ±‚**ï¼š
   - å‡†ç¡®æ¦‚æ‹¬æ–‡ç« çš„æ ¸å¿ƒä¸»é¢˜å’Œå…³é”®è¦ç‚¹
   - çªå‡ºæŠ€æœ¯ç‰¹ç‚¹ã€åº”ç”¨åœºæ™¯æˆ–è§£å†³çš„é—®é¢˜
   - ä½¿ç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„è¯­è¨€
   - é¿å…é‡å¤æ–‡ç« æ ‡é¢˜çš„å†…å®¹
3. **æ ¼å¼è¦æ±‚**ï¼š
   - ç›´æ¥è¿”å›æ‘˜è¦å†…å®¹ï¼Œæ— éœ€ä»»ä½•å‰ç¼€æˆ–åç¼€
   - ä½¿ç”¨ç®€æ´çš„é™ˆè¿°å¥
   - å¯ä»¥é€‚å½“ä½¿ç”¨æŠ€æœ¯æœ¯è¯­

æ–‡ç« æ ‡é¢˜ï¼š{page_title}

æ–‡ç« å†…å®¹ï¼š
{content[:2500]}

è¯·ç”Ÿæˆæ‘˜è¦ï¼š"""

        if service_name == 'claude':
            # Claude APIæ ¼å¼
            return {
                "model": service_config['model'],
                "max_tokens": service_config['max_tokens'],
                "temperature": service_config['temperature'],
                "messages": [
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]
            }
        elif service_name == 'gemini':
            # Gemini APIæ ¼å¼
            return {
                "contents": [
                    {
                        "parts": [
                            {
                                "text": prompt
                            }
                        ]
                    }
                ],
                "generationConfig": {
                    "temperature": service_config['temperature'],
                    "maxOutputTokens": service_config['max_tokens']
                }
            }
        else:
            # OpenAIæ ¼å¼ (OpenAI, DeepSeek, Azure OpenAI)
            system_content = {
                'zh': "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯æ–‡æ¡£æ‘˜è¦ä¸“å®¶ï¼Œæ“…é•¿æå–æ–‡ç« æ ¸å¿ƒè¦ç‚¹å¹¶ç”Ÿæˆç®€æ´å‡†ç¡®çš„ä¸­æ–‡æ‘˜è¦ã€‚",
                'en': "You are a professional technical documentation summary expert, skilled at extracting core points from articles and generating concise and accurate English summaries.",
                'both': "You are a professional technical documentation summary expert, skilled at extracting core points from articles and generating concise and accurate bilingual summaries in both Chinese and English."
            }
            
            return {
                "model": service_config['model'],
                "messages": [
                    {
                        "role": "system",
                        "content": system_content.get(self.summary_language, system_content['zh'])
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "max_tokens": service_config['max_tokens'] * (2 if self.summary_language == 'both' else 1),
                "temperature": service_config['temperature'],
                "top_p": 0.9
            }
    
    def extract_response_content(self, service_name, response_data):
        """ä»å“åº”ä¸­æå–å†…å®¹"""
        try:
            if service_name == 'claude':
                return response_data['content'][0]['text']
            elif service_name == 'gemini':
                return response_data['candidates'][0]['content']['parts'][0]['text']
            else:
                # OpenAIæ ¼å¼
                return response_data['choices'][0]['message']['content']
        except (KeyError, IndexError) as e:
            print(f"è§£æ{service_name}å“åº”å¤±è´¥: {e}")
            return None
    
    def generate_ai_summary_with_service(self, content, page_title, service_name):
        """ä½¿ç”¨æŒ‡å®šæœåŠ¡ç”Ÿæˆæ‘˜è¦"""
        if service_name not in self.ai_services:
            print(f"ä¸æ”¯æŒçš„AIæœåŠ¡: {service_name}")
            return None
        
        service_config = self.ai_services[service_name]
        
        # æ£€æŸ¥APIå¯†é’¥
        if not service_config['api_key'] or service_config['api_key'].startswith('your-'):
            print(f"{service_name} APIå¯†é’¥æœªé…ç½®")
            return None
        
        try:
            headers = self.build_headers(service_config)
            payload = self.build_payload(service_name, service_config, content, page_title)
            
            # å¯¹äºGoogle APIï¼Œæ·»åŠ APIå¯†é’¥åˆ°URL
            url = service_config['url']
            if service_name == 'gemini':
                url = f"{url}?key={service_config['api_key']}"
            
            response = requests.post(
                url,
                headers=headers,
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                summary = self.extract_response_content(service_name, result)
                
                if summary:
                    # æ¸…ç†å¯èƒ½çš„æ ¼å¼é—®é¢˜
                    summary = re.sub(r'^["""''`]+|["""''`]+$', '', summary.strip())
                    summary = re.sub(r'^\s*æ‘˜è¦[ï¼š:]\s*', '', summary)
                    summary = re.sub(r'^\s*æ€»ç»“[ï¼š:]\s*', '', summary)
                    summary = re.sub(r'^\s*Summary[ï¼š:]\s*', '', summary)
                    summary = re.sub(r'^\s*Abstract[ï¼š:]\s*', '', summary)
                    return summary
                
            else:
                print(f"{service_name} APIè¯·æ±‚å¤±è´¥: {response.status_code} - {response.text}")
                return None
                
        except requests.exceptions.RequestException as e:
            print(f"{service_name} APIè¯·æ±‚å¼‚å¸¸: {e}")
            return None
        except Exception as e:
            print(f"{service_name} æ‘˜è¦ç”Ÿæˆå¼‚å¸¸: {e}")
            return None
    
    def generate_ai_summary(self, content, page_title=""):
        """
        ç”ŸæˆAIæ‘˜è¦ï¼ˆå¸¦ç¼“å­˜é€»è¾‘ï¼‰
        
        Args:
            content (str): æ¸…ç†åçš„æ–‡ç« å†…å®¹
            page_title (str): æ–‡ç« æ ‡é¢˜
            
        Returns:
            tuple: (æ‘˜è¦å†…å®¹, ä½¿ç”¨çš„æœåŠ¡åç§°)
            
        ç”Ÿæˆé€»è¾‘ï¼š
        1. æ£€æŸ¥æ˜¯å¦åº”è¯¥ç”Ÿæˆæ–°æ‘˜è¦
        2. æŒ‰ä¼˜å…ˆçº§é¡ºåºå°è¯•ä¸åŒçš„AIæœåŠ¡
        3. è¿”å›ç¬¬ä¸€ä¸ªæˆåŠŸçš„ç»“æœ
        """
        # å¦‚æœé…ç½®ä¸ºä¸ç”Ÿæˆæ–°æ‘˜è¦ï¼ˆå¦‚CIä»…ç¼“å­˜æ¨¡å¼ï¼‰ï¼Œç›´æ¥è¿”å›
        if not self.should_generate_new_summary():
            print(f"ğŸ“¦ CIä»…ç¼“å­˜æ¨¡å¼ï¼Œè·³è¿‡æ‘˜è¦ç”Ÿæˆ")
            return None, 'ci_cache_only'
        
        # æŒ‰ä¼˜å…ˆçº§å°è¯•ä¸åŒçš„AIæœåŠ¡
        # é¦–å…ˆå°è¯•é»˜è®¤æœåŠ¡ï¼Œç„¶åæŒ‰fallbacké¡ºåºå°è¯•å…¶ä»–æœåŠ¡
        services_to_try = [self.default_service] + [
            s for s in self.service_fallback_order if s != self.default_service
        ]
        
        for service_name in services_to_try:
            if service_name in self.ai_services:
                print(f"ğŸ”„ å°è¯•ä½¿ç”¨ {service_name} ç”Ÿæˆæ‘˜è¦...")
                summary = self.generate_ai_summary_with_service(content, page_title, service_name)
                if summary:
                    return summary, service_name
        
        print("âš ï¸ æ‰€æœ‰AIæœåŠ¡å‡ä¸å¯ç”¨")
        return None, None
    
    def generate_fallback_summary(self, content, page_title=""):
        """
        ç”Ÿæˆå¤‡ç”¨æ‘˜è¦ï¼ˆå½“AIæœåŠ¡ä¸å¯ç”¨æ—¶ï¼‰
        
        Args:
            content (str): æ¸…ç†åçš„æ–‡ç« å†…å®¹
            page_title (str): æ–‡ç« æ ‡é¢˜
            
        Returns:
            str|None: å¤‡ç”¨æ‘˜è¦å†…å®¹ï¼Œå¦‚æœæ— æ³•ç”Ÿæˆåˆ™è¿”å›None
            
        å¤‡ç”¨æ‘˜è¦ç­–ç•¥ï¼š
        1. æ£€æŸ¥CIç¯å¢ƒæ˜¯å¦å…è®¸å¤‡ç”¨æ‘˜è¦
        2. ä½¿ç”¨å…³é”®è¯æå–å’Œå¥å­åˆ†æ
        3. æ ¹æ®è¯­è¨€è®¾ç½®ç”Ÿæˆç›¸åº”çš„æ‘˜è¦
        """
        # CIç¯å¢ƒæ£€æŸ¥ - å¦‚æœCIç¯å¢ƒç¦ç”¨äº†å¤‡ç”¨æ‘˜è¦ï¼Œç›´æ¥è¿”å›
        if self.env_config['is_ci'] and not self.env_config['ci_fallback']:
            print(f"ğŸš« CIç¯å¢ƒç¦ç”¨å¤‡ç”¨æ‘˜è¦")
            return None
        
        # ç§»é™¤æ ¼å¼ç¬¦å·
        clean_text = re.sub(r'^#+\s*', '', content, flags=re.MULTILINE)
        clean_text = re.sub(r'\*\*([^*]+)\*\*', r'\1', clean_text)
        clean_text = re.sub(r'\*([^*]+)\*', r'\1', clean_text)
        
        # åˆ†å‰²æˆå¥å­
        sentences = re.split(r'[\u3002\uff01\uff1f.!?]', clean_text)
        sentences = [s.strip() for s in sentences if len(s.strip()) > 15]
        
        # ä¼˜å…ˆé€‰æ‹©åŒ…å«å…³é”®è¯çš„å¥å­
        key_indicators = [
            'ä»‹ç»', 'è®²è§£', 'è¯´æ˜', 'åˆ†æ', 'æ¢è®¨', 'ç ”ç©¶', 'å®ç°', 'åº”ç”¨',
            'æ–¹æ³•', 'æŠ€æœ¯', 'ç®—æ³•', 'åŸç†', 'æ¦‚å¿µ', 'ç‰¹ç‚¹', 'ä¼˜åŠ¿', 'è§£å†³',
            'æ•™ç¨‹', 'æŒ‡å—', 'é…ç½®', 'å®‰è£…', 'éƒ¨ç½²', 'å¼€å‘', 'è®¾è®¡', 'æ„å»º'
        ]
        
        priority_sentences = []
        normal_sentences = []
        
        for sentence in sentences[:10]:  # å¤„ç†å‰10å¥
            if any(keyword in sentence for keyword in key_indicators):
                priority_sentences.append(sentence)
            else:
                normal_sentences.append(sentence)
    
        # ç»„åˆæ‘˜è¦
        selected_sentences = []
        total_length = 0
    
        # ä¼˜å…ˆä½¿ç”¨å…³é”®å¥å­
        for sentence in priority_sentences:
            if total_length + len(sentence) > 100:
                break
            selected_sentences.append(sentence)
            total_length += len(sentence)
    
        # å¦‚æœè¿˜æœ‰ç©ºé—´ï¼Œæ·»åŠ æ™®é€šå¥å­
        if total_length < 80:
            for sentence in normal_sentences:
                if total_length + len(sentence) > 100:
                    break
                selected_sentences.append(sentence)
                total_length += len(sentence)
    
        if selected_sentences:
            summary = '.'.join(selected_sentences) + '.'
            # ç®€åŒ–å†—é•¿çš„æ‘˜è¦
            if len(summary) > 120:
                summary = selected_sentences[0] + '.'
                
            # æ ¹æ®è¯­è¨€è®¾ç½®ç”Ÿæˆä¸åŒçš„å¤‡ç”¨æ‘˜è¦
            if self.summary_language == 'en':
                return self._generate_english_fallback(page_title)
            elif self.summary_language == 'both':
                zh_summary = summary
                en_summary = self._generate_english_fallback(page_title)
                return f"{zh_summary}\n\n{en_summary}"
            else:
                return summary
        else:
            # æ ¹æ®æ ‡é¢˜å’Œè¯­è¨€ç”Ÿæˆé€šç”¨æ‘˜è¦
            if self.summary_language == 'en':
                return self._generate_english_fallback(page_title)
            elif self.summary_language == 'both':
                zh_summary = self._generate_chinese_fallback(page_title)
                en_summary = self._generate_english_fallback(page_title)
                return f"{zh_summary}\n\n{en_summary}"
            else:
                return self._generate_chinese_fallback(page_title)
    
    def _generate_chinese_fallback(self, page_title=""):
        """ç”Ÿæˆä¸­æ–‡å¤‡ç”¨æ‘˜è¦"""
        if page_title:
            # æ ¹æ®æ ‡é¢˜ç”Ÿæˆé€šç”¨æ‘˜è¦
            if any(keyword in page_title for keyword in ['æ•™ç¨‹', 'æŒ‡å—', 'é…ç½®', 'å®‰è£…']):
                return f"æœ¬æ–‡ä»‹ç»äº†{page_title}çš„ç›¸å…³å†…å®¹ï¼ŒåŒ…æ‹¬å…·ä½“çš„æ“ä½œæ­¥éª¤å’Œæ³¨æ„äº‹é¡¹ï¼Œä¸ºè¯»è€…æä¾›å®ç”¨çš„æŠ€æœ¯æŒ‡å¯¼ã€‚"
            elif any(keyword in page_title for keyword in ['åˆ†æ', 'ç ”ç©¶', 'æ¢è®¨', 'åŸç†']):
                return f"æœ¬æ–‡æ·±å…¥åˆ†æäº†{page_title}çš„æ ¸å¿ƒæ¦‚å¿µå’ŒæŠ€æœ¯åŸç†ï¼Œä¸ºè¯»è€…æä¾›è¯¦ç»†çš„ç†è®ºè§£æå’Œå®è·µè§è§£ã€‚"
            elif any(keyword in page_title for keyword in ['å¼€å‘', 'æ„å»º', 'å®ç°', 'è®¾è®¡']):
                return f"æœ¬æ–‡è¯¦ç»†è®²è§£äº†{page_title}çš„å¼€å‘è¿‡ç¨‹å’Œå®ç°æ–¹æ³•ï¼Œåˆ†äº«äº†å®é™…çš„å¼€å‘ç»éªŒå’ŒæŠ€æœ¯æ–¹æ¡ˆã€‚"
            else:
                return f"æœ¬æ–‡å›´ç»•{page_title}å±•å¼€è®¨è®ºï¼Œä»‹ç»äº†ç›¸å…³çš„æŠ€æœ¯æ¦‚å¿µã€åº”ç”¨åœºæ™¯å’Œå®è·µæ–¹æ³•ã€‚"
        else:
            return "æœ¬æ–‡ä»‹ç»äº†ç›¸å…³çš„æŠ€æœ¯æ¦‚å¿µå’Œå®è·µæ–¹æ³•ï¼Œä¸ºè¯»è€…æä¾›æœ‰ä»·å€¼çš„å‚è€ƒä¿¡æ¯ã€‚"

    def _generate_english_fallback(self, page_title=""):
        """ç”Ÿæˆè‹±æ–‡å¤‡ç”¨æ‘˜è¦"""
        if page_title:
            # æ ¹æ®æ ‡é¢˜ç”Ÿæˆé€šç”¨æ‘˜è¦
            if any(keyword in page_title.lower() for keyword in ['tutorial', 'guide', 'setup', 'install', 'config']):
                return f"This article provides a comprehensive guide on {page_title}, including step-by-step instructions and important considerations for practical implementation."
            elif any(keyword in page_title.lower() for keyword in ['analysis', 'research', 'study', 'principle']):
                return f"This article presents an in-depth analysis of {page_title}, exploring core concepts and technical principles with detailed theoretical insights."
            elif any(keyword in page_title.lower() for keyword in ['develop', 'build', 'implement', 'design']):
                return f"This article explains the development process and implementation methods for {page_title}, sharing practical development experience and technical solutions."
            else:
                return f"This article discusses {page_title}, covering relevant technical concepts, application scenarios, and practical methods."
        else:
            return "This article introduces relevant technical concepts and practical methods, providing valuable reference information for readers."

    def is_ci_environment(self):
        """æ£€æµ‹æ˜¯å¦åœ¨ CI ç¯å¢ƒä¸­è¿è¡Œ"""
        # å¸¸è§çš„ CI ç¯å¢ƒå˜é‡
        ci_indicators = [
            'CI', 'CONTINUOUS_INTEGRATION',           # é€šç”¨ CI æ ‡è¯†
            'GITHUB_ACTIONS',                         # GitHub Actions
            'GITLAB_CI',                              # GitLab CI
            'JENKINS_URL',                            # Jenkins
            'TRAVIS',                                 # Travis CI
            'CIRCLECI',                               # CircleCI
            'AZURE_HTTP_USER_AGENT',                  # Azure DevOps
            'TEAMCITY_VERSION',                       # TeamCity
            'BUILDKITE',                              # Buildkite
            'CODEBUILD_BUILD_ID',                     # AWS CodeBuild
            'NETLIFY',                                # Netlify
            'VERCEL',                                 # Vercel
            'CF_PAGES',                               # Cloudflare Pages
        ]
        
        for indicator in ci_indicators:
            if os.getenv(indicator):
                return True
        
        return False
    
    def should_run_in_current_environment(self):
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥åœ¨å½“å‰ç¯å¢ƒä¸­è¿è¡Œ AI æ‘˜è¦"""
        return self._should_run
    
    def _get_ci_name(self):
        """è·å– CI ç¯å¢ƒåç§°"""
        if os.getenv('GITHUB_ACTIONS'):
            return 'GitHub Actions'
        elif os.getenv('GITLAB_CI'):
            return 'GitLab CI'
        elif os.getenv('JENKINS_URL'):
            return 'Jenkins'
        elif os.getenv('TRAVIS'):
            return 'Travis CI'
        elif os.getenv('CIRCLECI'):
            return 'CircleCI'
        elif os.getenv('AZURE_HTTP_USER_AGENT'):
            return 'Azure DevOps'
        elif os.getenv('NETLIFY'):
            return 'Netlify'
        elif os.getenv('VERCEL'):
            return 'Vercel'
        elif os.getenv('CF_PAGES'):
            return 'Cloudflare Pages'
        elif os.getenv('CODEBUILD_BUILD_ID'):
            return 'AWS CodeBuild'
        else:
            return 'Unknown CI'
    
    def _auto_migrate_cache(self):
        """è‡ªåŠ¨è¿ç§»ç¼“å­˜æ–‡ä»¶ï¼ˆä»…åœ¨éœ€è¦æ—¶æ‰§è¡Œä¸€æ¬¡ï¼‰"""
        # å¦‚æœç¦ç”¨äº†ç¼“å­˜åŠŸèƒ½ï¼Œè·³è¿‡ç¼“å­˜è¿ç§»
        if not self.ci_config.get('cache_enabled', True):
            return
            
        old_cache_dir = Path("site/.ai_cache")
        new_cache_dir = Path(".ai_cache")
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦è¿ç§»
        if old_cache_dir.exists() and not new_cache_dir.exists():
            print("ğŸ”„ æ£€æµ‹åˆ°æ—§ç¼“å­˜ç›®å½•ï¼Œå¼€å§‹è‡ªåŠ¨è¿ç§»...")
            
            try:
                # åˆ›å»ºæ–°ç›®å½•
                new_cache_dir.mkdir(exist_ok=True)
                
                # å¤åˆ¶æ–‡ä»¶
                cache_files = list(old_cache_dir.glob("*.json"))
                copied_count = 0
                
                for cache_file in cache_files:
                    target_file = new_cache_dir / cache_file.name
                    try:
                        shutil.copy2(cache_file, target_file)
                        copied_count += 1
                    except Exception as e:
                        print(f"âš ï¸ å¤åˆ¶ç¼“å­˜æ–‡ä»¶å¤±è´¥ {cache_file.name}: {e}")
                
                if copied_count > 0:
                    print(f"âœ… è‡ªåŠ¨è¿ç§»å®Œæˆï¼å…±è¿ç§» {copied_count} ä¸ªç¼“å­˜æ–‡ä»¶")
                    print("ğŸ’¡ æç¤ºï¼šè¯·å°† .ai_cache ç›®å½•æäº¤åˆ° Git ä»“åº“")
                else:
                    print("â„¹ï¸ æ²¡æœ‰ç¼“å­˜æ–‡ä»¶éœ€è¦è¿ç§»")
                    
            except Exception as e:
                print(f"âŒ è‡ªåŠ¨è¿ç§»å¤±è´¥: {e}")
        
        elif new_cache_dir.exists():
            # æ–°ç¼“å­˜ç›®å½•å·²å­˜åœ¨ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶
            cache_files = list(new_cache_dir.glob("*.json"))
            if cache_files:
                is_ci = self.is_ci_environment()
                env_desc = '(CI)' if is_ci else '(æœ¬åœ°)'
                print(f"ğŸ“¦ å‘ç°æ ¹ç›®å½•ç¼“å­˜ {env_desc}ï¼Œå…± {len(cache_files)} ä¸ªç¼“å­˜æ–‡ä»¶")
    
    def process_page(self, markdown, page, config):
        """
        å¤„ç†é¡µé¢çš„ä¸»è¦å…¥å£å‡½æ•°
        
        Args:
            markdown (str): é¡µé¢çš„markdownå†…å®¹
            page: MkDocsé¡µé¢å¯¹è±¡
            config: MkDocsé…ç½®å¯¹è±¡
            
        Returns:
            str: å¤„ç†åçš„markdownå†…å®¹ï¼ˆå¯èƒ½åŒ…å«AIæ‘˜è¦ï¼‰
            
        å¤„ç†æµç¨‹ï¼š
        1. æ£€æŸ¥æ˜¯å¦åº”è¯¥åœ¨å½“å‰ç¯å¢ƒè¿è¡Œ
        2. æ£€æŸ¥é¡µé¢æ˜¯å¦éœ€è¦ç”Ÿæˆæ‘˜è¦
        3. æ¸…ç†å†…å®¹å¹¶ç”Ÿæˆæ‘˜è¦
        4. ä½¿ç”¨ç¼“å­˜æœºåˆ¶ä¼˜åŒ–æ€§èƒ½
        5. æ ¼å¼åŒ–å¹¶æ’å…¥æ‘˜è¦
        """
        # æ­¥éª¤1ï¼šç¯å¢ƒæ£€æŸ¥ - å¦‚æœå½“å‰ç¯å¢ƒä¸åº”è¯¥è¿è¡Œï¼Œç›´æ¥è¿”å›åŸå†…å®¹
        if not self._should_run:
            return markdown
        
        # æ­¥éª¤2ï¼šé¡µé¢æ£€æŸ¥ - æ£€æŸ¥è¯¥é¡µé¢æ˜¯å¦éœ€è¦ç”Ÿæˆæ‘˜è¦
        if not self.should_generate_summary(page, markdown):
            return markdown
        
        # æ­¥éª¤3ï¼šå†…å®¹é¢„å¤„ç†
        clean_content = self.clean_content_for_ai(markdown)
        if len(clean_content) < 100:
            print(f"ğŸ“„ å†…å®¹å¤ªçŸ­ï¼Œè·³è¿‡: {page.file.src_path}")
            return markdown
        
        # æ­¥éª¤4ï¼šç¼“å­˜å¤„ç†
        content_hash = self.get_content_hash(clean_content)
        page_title = getattr(page, 'title', '')
        
        # 4.1 å°è¯•è·å–ç¼“å­˜
        cached_summary = self.get_cached_summary(content_hash)
        if cached_summary:
            # ç¼“å­˜å‘½ä¸­ - ç›´æ¥ä½¿ç”¨ç¼“å­˜çš„æ‘˜è¦
            summary = cached_summary.get('summary', '')
            ai_service = cached_summary.get('service', 'cached')
            env_desc = 'CI' if self.env_config['is_ci'] else 'æœ¬åœ°'
            print(f"âœ… ä½¿ç”¨ç¼“å­˜æ‘˜è¦ ({env_desc}): {page.file.src_path}")
        else:
            # 4.2 ç¼“å­˜æœªå‘½ä¸­ - ç”Ÿæˆæ–°æ‘˜è¦
            env_desc = 'CI' if self.env_config['is_ci'] else 'æœ¬åœ°'
            print(f"ğŸ¤– ç”ŸæˆAIæ‘˜è¦ ({env_desc}): {page.file.src_path}")
            
            # å°è¯•AIæ‘˜è¦
            summary, ai_service = self.generate_ai_summary(clean_content, page_title)
            
            # 4.3 å¦‚æœAIæ‘˜è¦å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ‘˜è¦
            if not summary:
                summary = self.generate_fallback_summary(clean_content, page_title)
                if summary:
                    ai_service = 'fallback'
                    print(f"ğŸ“ ä½¿ç”¨å¤‡ç”¨æ‘˜è¦ ({env_desc}): {page.file.src_path}")
                else:
                    print(f"âŒ æ— æ³•ç”Ÿæˆæ‘˜è¦ ({env_desc}): {page.file.src_path}")
                    return markdown
            else:
                print(f"âœ… AIæ‘˜è¦ç”ŸæˆæˆåŠŸ ({ai_service}) ({env_desc}): {page.file.src_path}")
            
            # 4.4 ä¿å­˜æ–°ç”Ÿæˆçš„æ‘˜è¦åˆ°ç¼“å­˜
            if summary:
                self.save_summary_cache(content_hash, {
                    'summary': summary,
                    'service': ai_service,
                    'page_title': page_title
                })
        
        # æ­¥éª¤5ï¼šæ ¼å¼åŒ–å¹¶è¿”å›æœ€ç»ˆå†…å®¹
        if summary:
            summary_html = self.format_summary(summary, ai_service)
            return summary_html + '\n\n' + markdown
        
        return markdown
    
    def should_generate_summary(self, page, markdown):
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ç”Ÿæˆæ‘˜è¦"""
        # æ£€æŸ¥é¡µé¢å…ƒæ•°æ®
        if hasattr(page, 'meta'):
            # æ˜ç¡®ç¦ç”¨
            if page.meta.get('ai_summary') == False:
                return False
            
            # å¼ºåˆ¶å¯ç”¨
            if page.meta.get('ai_summary') == True:
                return True
        
        # è·å–æ–‡ä»¶è·¯å¾„
        src_path = page.file.src_path.replace('\\', '/')  # ç»Ÿä¸€è·¯å¾„åˆ†éš”ç¬¦
        
        # æ£€æŸ¥æ’é™¤æ¨¡å¼
        if any(pattern in src_path for pattern in self.exclude_patterns):
            return False
        
        # æ£€æŸ¥æ’é™¤çš„ç‰¹å®šæ–‡ä»¶
        if src_path in self.exclude_files:
            return False
        
        # æ£€æŸ¥æ˜¯å¦åœ¨å¯ç”¨çš„æ–‡ä»¶å¤¹ä¸­
        for folder in self.enabled_folders:
            if src_path.startswith(folder) or f'/{folder}' in src_path:
                folder_name = folder.rstrip('/')
                lang_desc = {'zh': 'ä¸­æ–‡', 'en': 'è‹±æ–‡', 'both': 'åŒè¯­'}
                print(f"ğŸ¯ {folder_name}æ–‡ä»¶å¤¹æ–‡ç« æ£€æµ‹åˆ°ï¼Œå¯ç”¨{lang_desc.get(self.summary_language, 'ä¸­æ–‡')}AIæ‘˜è¦: {src_path}")
                return True
        
        # é»˜è®¤ä¸ç”Ÿæˆæ‘˜è¦
        return False
    
    def format_summary(self, summary, ai_service):
        """æ ¼å¼åŒ–æ‘˜è¦æ˜¾ç¤ºï¼ˆåŒ…å«CIç¯å¢ƒæ ‡è¯†ï¼‰"""
        # æ ¹æ®è¯­è¨€è®¾ç½®æ˜¾ç¤ºä¸åŒçš„æ ‡é¢˜
        service_names = {
            'zh': {
                'deepseek': 'AIæ™ºèƒ½æ‘˜è¦ (DeepSeek)',
                'openai': 'AIæ™ºèƒ½æ‘˜è¦ (ChatGPT)',
                'azure_openai': 'AIæ™ºèƒ½æ‘˜è¦ (Azure OpenAI)',
                'claude': 'AIæ™ºèƒ½æ‘˜è¦ (Claude)',
                'gemini': 'AIæ™ºèƒ½æ‘˜è¦ (Gemini)',
                'fallback': 'è‡ªåŠ¨æ‘˜è¦',
                'cached': 'AIæ™ºèƒ½æ‘˜è¦',
                'ci_cache_only': 'AIæ™ºèƒ½æ‘˜è¦ (ç¼“å­˜)'
            },
            'en': {
                'deepseek': 'AI Summary (DeepSeek)',
                'openai': 'AI Summary (ChatGPT)',
                'azure_openai': 'AI Summary (Azure OpenAI)',
                'claude': 'AI Summary (Claude)',
                'gemini': 'AI Summary (Gemini)',
                'fallback': 'Auto Summary',
                'cached': 'AI Summary',
                'ci_cache_only': 'AI Summary (Cached)'
            },
            'both': {
                'deepseek': 'AIæ™ºèƒ½æ‘˜è¦ / AI Summary (DeepSeek)',
                'openai': 'AIæ™ºèƒ½æ‘˜è¦ / AI Summary (ChatGPT)',
                'azure_openai': 'AIæ™ºèƒ½æ‘˜è¦ / AI Summary (Azure OpenAI)',
                'claude': 'AIæ™ºèƒ½æ‘˜è¦ / AI Summary (Claude)',
                'gemini': 'AIæ™ºèƒ½æ‘˜è¦ / AI Summary (Gemini)',
                'fallback': 'è‡ªåŠ¨æ‘˜è¦ / Auto Summary',
                'cached': 'AIæ™ºèƒ½æ‘˜è¦ / AI Summary',
                'ci_cache_only': 'AIæ™ºèƒ½æ‘˜è¦ / AI Summary (ç¼“å­˜)'
            }
        }
        
        name_config = service_names.get(self.summary_language, service_names['zh'])
        service_name = name_config.get(ai_service, name_config['fallback'])
        
        # å›¾æ ‡å’Œé¢œè‰²é…ç½®
        icon = 'ğŸ’¾' if ai_service not in ['fallback', 'ci_cache_only'] else 'ğŸ“'
        color = 'info' if ai_service not in ['fallback', 'ci_cache_only'] else 'tip'
        
        return f'''!!! {color} "{icon} {service_name}"
    {summary}

'''

# åˆ›å»ºå…¨å±€å®ä¾‹
ai_summary_generator = AISummaryGenerator()

# ğŸ”§ é…ç½®å‡½æ•°
def configure_ai_summary(enabled_folders=None, exclude_patterns=None, exclude_files=None, 
                        ai_service=None, language='zh',
                        cache_enabled=None, cache_expire_days=None,
                        ci_enabled=None, local_enabled=None, ci_cache_only=None, ci_fallback=None):
    """
    ç®€åŒ–çš„AIæ‘˜è¦é…ç½®å‡½æ•°
    
    è¿™æ˜¯ç”¨æˆ·é…ç½®AIæ‘˜è¦åŠŸèƒ½çš„ä¸»è¦æ¥å£ï¼Œæä¾›äº†æ‰€æœ‰ä¸»è¦é…ç½®é€‰é¡¹ã€‚
    
    Args:
        enabled_folders (list): å¯ç”¨AIæ‘˜è¦çš„æ–‡ä»¶å¤¹åˆ—è¡¨
            ä¾‹ï¼š['blog/', 'docs/', 'tutorials/']
            
        exclude_patterns (list): æ’é™¤çš„æ–‡ä»¶æ¨¡å¼åˆ—è¡¨
            ä¾‹ï¼š['404.md', 'tag.md', 'tags.md']
            
        exclude_files (list): æ’é™¤çš„ç‰¹å®šæ–‡ä»¶åˆ—è¡¨
            ä¾‹ï¼š['blog/index.md', 'docs/index.md']
            
        ai_service (str): ä½¿ç”¨çš„AIæœåŠ¡
            é€‰é¡¹ï¼š'deepseek', 'openai', 'claude', 'gemini'
            
        language (str): æ‘˜è¦è¯­è¨€
            é€‰é¡¹ï¼š'zh'(ä¸­æ–‡), 'en'(è‹±æ–‡), 'both'(åŒè¯­)
            
        cache_enabled (bool): æ˜¯å¦å¯ç”¨ç¼“å­˜ç³»ç»Ÿ
            True: å¯ç”¨ç¼“å­˜ï¼Œæé«˜æ€§èƒ½ï¼Œå‡å°‘APIè°ƒç”¨
            False: ç¦ç”¨ç¼“å­˜ï¼Œæ€»æ˜¯ç”Ÿæˆæ–°æ‘˜è¦
            
        cache_expire_days (int): ç¼“å­˜è¿‡æœŸå¤©æ•°
            é»˜è®¤ï¼š7å¤©ï¼Œè¶…è¿‡æ­¤æ—¶é—´çš„ç¼“å­˜ä¼šè¢«è‡ªåŠ¨æ¸…ç†
            
        ci_enabled (bool): CIç¯å¢ƒæ˜¯å¦å¯ç”¨AIæ‘˜è¦
            True: åœ¨CI/CDç¯å¢ƒä¸­å¯ç”¨æ‘˜è¦ç”Ÿæˆ
            False: åœ¨CI/CDç¯å¢ƒä¸­ç¦ç”¨æ‘˜è¦ç”Ÿæˆ
            
        local_enabled (bool): æœ¬åœ°ç¯å¢ƒæ˜¯å¦å¯ç”¨AIæ‘˜è¦
            True: åœ¨æœ¬åœ°å¼€å‘ç¯å¢ƒä¸­å¯ç”¨æ‘˜è¦ç”Ÿæˆ
            False: åœ¨æœ¬åœ°å¼€å‘ç¯å¢ƒä¸­ç¦ç”¨æ‘˜è¦ç”Ÿæˆ
            
        ci_cache_only (bool): CIç¯å¢ƒæ˜¯å¦ä»…ä½¿ç”¨ç¼“å­˜
            True: CIç¯å¢ƒåªä½¿ç”¨å·²æœ‰ç¼“å­˜ï¼Œä¸ç”Ÿæˆæ–°æ‘˜è¦ï¼ˆèŠ‚çœæˆæœ¬ï¼‰
            False: CIç¯å¢ƒå¯ä»¥ç”Ÿæˆæ–°æ‘˜è¦
            
        ci_fallback (bool): CIç¯å¢ƒæ˜¯å¦å¯ç”¨å¤‡ç”¨æ‘˜è¦
            True: å½“AIæœåŠ¡ä¸å¯ç”¨æ—¶ï¼Œç”Ÿæˆç®€å•çš„å¤‡ç”¨æ‘˜è¦
            False: AIæœåŠ¡ä¸å¯ç”¨æ—¶è·³è¿‡æ‘˜è¦ç”Ÿæˆ
    
    Example:
        # åŸºç¡€é…ç½® - ä¸ºåšå®¢å’Œæ–‡æ¡£å¯ç”¨ä¸­æ–‡æ‘˜è¦
        configure_ai_summary(
            enabled_folders=['blog/', 'docs/'],
            language='zh'
        )
        
        # å¼€å‘æ¨¡å¼ - ç¦ç”¨ç¼“å­˜ï¼Œæ€»æ˜¯ç”Ÿæˆæ–°æ‘˜è¦
        configure_ai_summary(
            enabled_folders=['blog/'],
            cache_enabled=False
        )
        
        # ç”Ÿäº§æ¨¡å¼ - CIç¯å¢ƒä»…ä½¿ç”¨ç¼“å­˜ï¼ŒèŠ‚çœAPIæˆæœ¬
        configure_ai_summary(
            enabled_folders=['blog/'],
            ci_cache_only=True
        )
        
        # å®Œå…¨è‡ªå®šä¹‰é…ç½®
        configure_ai_summary(
            enabled_folders=['posts/', 'articles/'],
            exclude_patterns=['draft.md', 'private.md'],
            ai_service='deepseek',
            language='both',
            cache_expire_days=14,
            ci_enabled=True,
            local_enabled=False,
            ci_cache_only=True,
            ci_fallback=True
        )
    """
    # æ–‡ä»¶å¤¹å’Œæ’é™¤è§„åˆ™é…ç½®
    ai_summary_generator.configure_folders(enabled_folders, exclude_patterns, exclude_files)
    
    # è¯­è¨€é…ç½® - å¦‚æœæœ‰å˜æ›´ä¼šè§¦å‘ç¼“å­˜æ¸…ç†
    if language != ai_summary_generator.summary_language:
        ai_summary_generator.summary_language = language
        print(f"ğŸŒ è¯­è¨€è®¾ç½®: {language}")
    
    # AIæœåŠ¡é…ç½® - å¦‚æœæœ‰å˜æ›´ä¼šè§¦å‘ç¼“å­˜æ¸…ç†
    if ai_service and ai_service != ai_summary_generator.default_service:
        ai_summary_generator.default_service = ai_service
        print(f"ğŸ¤– AIæœåŠ¡: {ai_service}")
    
    # ç¼“å­˜ç³»ç»Ÿé…ç½®
    if cache_enabled is not None:
        ai_summary_generator.cache_config['enabled'] = cache_enabled
        print(f"ğŸ’¾ ç¼“å­˜åŠŸèƒ½: {'å¯ç”¨' if cache_enabled else 'ç¦ç”¨'}")
    
    if cache_expire_days is not None:
        ai_summary_generator.cache_config['expire_days'] = cache_expire_days
        print(f"â° ç¼“å­˜è¿‡æœŸ: {cache_expire_days}å¤©")
    
    # ç¯å¢ƒè¡Œä¸ºé…ç½®
    if ci_enabled is not None:
        ai_summary_generator.env_config['ci_enabled'] = ci_enabled
        print(f"ğŸš€ CIç¯å¢ƒ: {'å¯ç”¨' if ci_enabled else 'ç¦ç”¨'}")
    
    if local_enabled is not None:
        ai_summary_generator.env_config['local_enabled'] = local_enabled
        print(f"ğŸ’» æœ¬åœ°ç¯å¢ƒ: {'å¯ç”¨' if local_enabled else 'ç¦ç”¨'}")
    
    if ci_cache_only is not None:
        ai_summary_generator.env_config['ci_cache_only'] = ci_cache_only
        print(f"ğŸ“¦ CIä»…ç¼“å­˜: {'å¯ç”¨' if ci_cache_only else 'ç¦ç”¨'}")
    
    if ci_fallback is not None:
        ai_summary_generator.env_config['ci_fallback'] = ci_fallback
        print(f"ğŸ“ CIå¤‡ç”¨æ‘˜è¦: {'å¯ç”¨' if ci_fallback else 'ç¦ç”¨'}")

def on_page_markdown(markdown, page, config, files):
    """
    MkDocs hookå…¥å£ç‚¹
    
    è¿™æ˜¯MkDocsæ¡†æ¶è°ƒç”¨çš„ä¸»è¦å…¥å£å‡½æ•°ï¼Œæ¯å½“å¤„ç†ä¸€ä¸ªé¡µé¢æ—¶éƒ½ä¼šè°ƒç”¨ã€‚
    
    Args:
        markdown (str): é¡µé¢çš„åŸå§‹markdownå†…å®¹
        page: MkDocsé¡µé¢å¯¹è±¡ï¼ŒåŒ…å«é¡µé¢å…ƒæ•°æ®
        config: MkDocså…¨å±€é…ç½®å¯¹è±¡
        files: æ‰€æœ‰æ–‡ä»¶çš„åˆ—è¡¨
        
    Returns:
        str: å¤„ç†åçš„markdownå†…å®¹ï¼ˆå¯èƒ½åŒ…å«AIæ‘˜è¦ï¼‰
    """
    return ai_summary_generator.process_page(markdown, page, config)
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import json
import base64
import hashlib
import time
from datetime import datetime
from typing import Dict, Any, Optional

def get_api_key():
    """ä»ç¯å¢ƒå˜é‡è·å–APIå¯†é’¥ï¼Œæ”¯æŒå¤šä¸ªå¤‡ç”¨å¯†é’¥"""
    # æ”¯æŒå¤šä¸ªAPIå¯†é’¥æº
    api_keys = [
        os.getenv('GLM_API_KEY'),
        os.getenv('ZHIPU_API_KEY'),
        os.getenv('BIGMODEL_API_KEY')
    ]
    
    api_key = next((key for key in api_keys if key), None)
    if not api_key:
        raise ValueError("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ GLM_API_KEY, ZHIPU_API_KEY æˆ– BIGMODEL_API_KEY")
    return api_key

def get_environment_config():
    """æ ¹æ®ç¯å¢ƒè·å–ä¼˜åŒ–é…ç½®"""
    env = os.getenv('NODE_ENV', 'development').lower()
    
    if env == 'production':
        return {
            'timeout': 12000,
            'maxRetries': 5,
            'batchSize': 12,
            'maxConcurrent': 6,
            'batchDelay': 80,
            'cacheEnabled': True,
            'compressionEnabled': True,
            'streamingEnabled': True
        }
    elif env == 'development':
        return {
            'timeout': 8000,
            'maxRetries': 3,
            'batchSize': 8,
            'maxConcurrent': 4,
            'batchDelay': 100,
            'cacheEnabled': True,
            'compressionEnabled': False,
            'streamingEnabled': False
        }
    else:  # testing
        return {
            'timeout': 5000,
            'maxRetries': 2,
            'batchSize': 4,
            'maxConcurrent': 2,
            'batchDelay': 200,
            'cacheEnabled': False,
            'compressionEnabled': False,
            'streamingEnabled': False
        }

def generate_config_hash(config):
    """ç”Ÿæˆé…ç½®å“ˆå¸Œï¼Œç”¨äºç‰ˆæœ¬æ§åˆ¶"""
    config_str = json.dumps(config, sort_keys=True)
    return hashlib.sha256(config_str.encode()).hexdigest()[:16]

def get_performance_profile():
    """æ ¹æ®ç³»ç»Ÿæ€§èƒ½è·å–ä¼˜åŒ–é…ç½®"""
    # å¯ä»¥æ ¹æ®ç³»ç»Ÿèµ„æºåŠ¨æ€è°ƒæ•´
    profile = os.getenv('PERFORMANCE_PROFILE', 'balanced').lower()
    
    profiles = {
        'high_performance': {
            'batchSize': 16,
            'maxConcurrent': 8,
            'timeout': 15000,
            'batchDelay': 50,
            'aggressiveOptimization': True
        },
        'balanced': {
            'batchSize': 10,
            'maxConcurrent': 5,
            'timeout': 10000,
            'batchDelay': 80,
            'aggressiveOptimization': False
        },
        'conservative': {
            'batchSize': 6,
            'maxConcurrent': 3,
            'timeout': 8000,
            'batchDelay': 120,
            'aggressiveOptimization': False
        }
    }
    
    return profiles.get(profile, profiles['balanced'])

def create_advanced_config():
    """åˆ›å»ºé«˜çº§æ™ºèƒ½é…ç½®"""
    api_key = get_api_key()
    env_config = get_environment_config()
    perf_profile = get_performance_profile()
    
    # åˆå¹¶é…ç½®ï¼Œæ€§èƒ½é…ç½®ä¼˜å…ˆçº§æœ€é«˜
    merged_config = {**env_config, **perf_profile}
    
    # åŸºç¡€é…ç½®
    config = {
        'endpoint': os.getenv('GLM_ENDPOINT', 'https://open.bigmodel.cn/api/paas/v4/chat/completions'),
        'model': os.getenv('GLM_MODEL', 'glm-4-flash'),
        **merged_config,
        
        # æ™ºèƒ½æ‰¹å¤„ç†é…ç½®
        'adaptiveBatching': True,
        'minBatchSize': max(2, merged_config.get('batchSize', 8) // 4),
        'maxBatchSize': min(25, merged_config.get('batchSize', 8) * 2),
        'dynamicBatchAdjustment': True,
        
        # é«˜çº§æ€§èƒ½é…ç½®
        'preloadCache': True,
        'intelligentRetry': True,
        'adaptiveTimeout': True,
        'loadBalancing': False,  # å•APIç«¯ç‚¹æ—¶å…³é—­
        'connectionPooling': True,
        'requestCompression': True,
        
        # è´¨é‡æ§åˆ¶
        'qualityThreshold': float(os.getenv('QUALITY_THRESHOLD', '0.85')),
        'fallbackModel': os.getenv('FALLBACK_MODEL', 'glm-4'),
        'validateTranslation': True,
        'autoCorrection': True,
        
        # ç›‘æ§å’Œè°ƒè¯•
        'enableMetrics': True,
        'enableDebugLog': os.getenv('DEBUG', 'false').lower() == 'true',
        'performanceTracking': True,
        'errorReporting': True,
        
        # å®‰å…¨é…ç½®
        'rateLimitProtection': True,
        'apiKeyRotation': False,  # æš‚ä¸æ”¯æŒ
        'requestSigning': True
    }
    
    # ç¼–ç APIå¯†é’¥ï¼ˆæ”¯æŒå¤šé‡ç¼–ç ï¼‰
    encoded_key = base64.b64encode(api_key.encode()).decode()
    
    return config, encoded_key

def validate_config(config: Dict[str, Any]) -> bool:
    """éªŒè¯é…ç½®çš„æœ‰æ•ˆæ€§"""
    required_fields = ['endpoint', 'model', 'timeout', 'batchSize', 'maxConcurrent']
    
    for field in required_fields:
        if field not in config:
            print(f"âŒ é…ç½®éªŒè¯å¤±è´¥: ç¼ºå°‘å¿…éœ€å­—æ®µ {field}")
            return False
    
    # éªŒè¯æ•°å€¼èŒƒå›´
    if config['timeout'] < 1000 or config['timeout'] > 30000:
        print("âŒ é…ç½®éªŒè¯å¤±è´¥: timeout åº”åœ¨ 1000-30000ms èŒƒå›´å†…")
        return False
    
    if config['batchSize'] < 1 or config['batchSize'] > 50:
        print("âŒ é…ç½®éªŒè¯å¤±è´¥: batchSize åº”åœ¨ 1-50 èŒƒå›´å†…")
        return False
    
    if config['maxConcurrent'] < 1 or config['maxConcurrent'] > 20:
        print("âŒ é…ç½®éªŒè¯å¤±è´¥: maxConcurrent åº”åœ¨ 1-20 èŒƒå›´å†…")
        return False
    
    print("âœ… é…ç½®éªŒè¯é€šè¿‡")
    return True

def generate_secure_config():
    """ç”Ÿæˆå®‰å…¨çš„ç¿»è¯‘é…ç½®"""
    
    try:
        # åˆ›å»ºé«˜çº§é…ç½®
        secure_config, encoded_key = create_advanced_config()
        
        print(f"âœ… æ‰¾åˆ°APIå¯†é’¥ï¼Œç¯å¢ƒ: {os.getenv('NODE_ENV', 'development')}")
        
        # éªŒè¯é…ç½®
        if not validate_config(secure_config):
            return False
            
    except ValueError as e:
        print(f"âŒ {e}")
        return False
    
    # ç”Ÿæˆé…ç½®å“ˆå¸Œï¼ˆç”¨äºéªŒè¯ï¼‰
    config_hash = generate_config_hash(secure_config)
    
    # æ·»åŠ å…ƒæ•°æ®
    secure_config.update({
        "configHash": config_hash,
        "generated": datetime.now().isoformat(),
        "environment": os.getenv('NODE_ENV', 'development'),
        "version": "2.0.0",
        "generator": "advanced-config-generator"
    })
    
    # ç”ŸæˆJavaScripté…ç½®æ–‡ä»¶ - åŒ…å«é«˜çº§æ™ºèƒ½ä¼˜åŒ–åŠŸèƒ½
    js_config = f"""// è‡ªåŠ¨ç”Ÿæˆçš„é«˜æ€§èƒ½æ™ºèƒ½ç¿»è¯‘é…ç½® - è¯·å‹¿æ‰‹åŠ¨ç¼–è¾‘
// ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
// ç¯å¢ƒ: {secure_config["environment"]}
// ä¼˜åŒ–ç‰¹æ€§: è‡ªé€‚åº”æ‰¹å¤„ç†ã€æ™ºèƒ½é‡è¯•ã€æ€§èƒ½ç›‘æ§ã€è´¨é‡æ§åˆ¶
window.GLM_TRANSLATE_CONFIG = {{
  endpoint: '{secure_config["endpoint"]}',
  model: '{secure_config["model"]}',
  maxRetries: {secure_config["maxRetries"]},
  timeout: {secure_config["timeout"]},
  batchSize: {secure_config["batchSize"]},
  batchDelay: {secure_config["batchDelay"]},
  maxConcurrent: {secure_config["maxConcurrent"]},
  
  // é«˜çº§é…ç½®
  adaptiveBatching: {str(secure_config["adaptiveBatching"]).lower()},
  minBatchSize: {secure_config["minBatchSize"]},
  maxBatchSize: {secure_config["maxBatchSize"]},
  dynamicBatchAdjustment: {str(secure_config["dynamicBatchAdjustment"]).lower()},
  preloadCache: {str(secure_config["preloadCache"]).lower()},
  intelligentRetry: {str(secure_config["intelligentRetry"]).lower()},
  adaptiveTimeout: {str(secure_config["adaptiveTimeout"]).lower()},
  cacheEnabled: {str(secure_config["cacheEnabled"]).lower()},
  compressionEnabled: {str(secure_config["compressionEnabled"]).lower()},
  streamingEnabled: {str(secure_config["streamingEnabled"]).lower()},
  
  // ç¿»è¯‘ä¼˜åŒ–é…ç½®
  alwaysFromOriginal: true,  // å§‹ç»ˆä»åŸæ–‡ç¿»è¯‘ï¼Œæå‡è´¨é‡å’Œé€Ÿåº¦
  originalLanguage: 'chinese_simplified',  // åŸæ–‡è¯­è¨€
  
  // è´¨é‡æ§åˆ¶
  qualityThreshold: {secure_config["qualityThreshold"]},
  fallbackModel: '{secure_config["fallbackModel"]}',
  validateTranslation: {str(secure_config["validateTranslation"]).lower()},
  
  // ç›‘æ§é…ç½®
  enableMetrics: {str(secure_config["enableMetrics"]).lower()},
  enableDebugLog: {str(secure_config["enableDebugLog"]).lower()},
  performanceTracking: {str(secure_config["performanceTracking"]).lower()},
  
  configHash: '{secure_config["configHash"]}',
  environment: '{secure_config["environment"]}',
  // ç¼–ç åçš„å¯†é’¥ï¼ˆä»…åœ¨HTTPSç¯å¢ƒä¸‹ä½¿ç”¨ï¼‰
  _k: '{encoded_key}',
  
  // æ€§èƒ½æŒ‡æ ‡
  metrics: {{
    requestCount: 0,
    successCount: 0,
    errorCount: 0,
    averageResponseTime: 0,
    cacheHitRate: 0
  }},
  
  // æ™ºèƒ½è¯æ±‡æ£€æµ‹é…ç½®
  skipPatterns: [
    /^[a-zA-Z\\s\\-_.,!?()\\[\\]{{}}:;"']+$/,  // çº¯è‹±æ–‡
    /\\b(GitHub|API|JSON|HTML|CSS|JavaScript|Python|React|Vue|Angular|Node\\.js)\\b/,  // æŠ€æœ¯æœ¯è¯­
    /^https?:\\/\\//,  // URL
    /^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{{2,}}$/  // é‚®ç®±
  ],
  
  // ä¸“æœ‰åè¯åˆ—è¡¨ï¼ˆä¸ç¿»è¯‘ï¼‰
  properNouns: [
    'GitHub', 'Material', 'MkDocs', 'JavaScript', 'Python', 'API', 'JSON', 'HTML', 'CSS',
    'Wcowin', 'GLM', 'OpenAI', 'Google', 'Microsoft', 'Apple', 'Linux', 'Windows', 'macOS',
    'React', 'Vue', 'Angular', 'Node.js', 'npm', 'yarn', 'webpack', 'TypeScript',
    'Docker', 'Kubernetes', 'AWS', 'Azure', 'GCP', 'Firebase', 'MongoDB', 'MySQL',
    'Redis', 'Nginx', 'Apache', 'Ubuntu', 'CentOS', 'Debian', 'iOS', 'Android'
  ]
}};

// è§£ç å‡½æ•°
window.GLM_TRANSLATE_CONFIG.getApiKey = function() {{
  if (location.protocol !== 'https:' && location.hostname !== 'localhost') {{
    console.warn('ç¿»è¯‘åŠŸèƒ½ä»…åœ¨HTTPSç¯å¢ƒä¸‹å¯ç”¨');
    return null;
  }}
  try {{
    return atob(this._k);
  }} catch (e) {{
    console.error('é…ç½®è§£æå¤±è´¥');
    return null;
  }}
}};

// æ™ºèƒ½è¯æ±‡æ£€æµ‹å‡½æ•°
window.GLM_TRANSLATE_CONFIG.shouldTranslate = function(text) {{
  if (!text || text.length < 3) return false;
  
  // æ£€æŸ¥è·³è¿‡æ¨¡å¼
  for (const pattern of this.skipPatterns) {{
    if (pattern.test(text)) return false;
  }}
  
  // æ£€æŸ¥ä¸“æœ‰åè¯
  for (const noun of this.properNouns) {{
    if (text.includes(noun)) return false;
  }}
  
  return true;
}};

// åŠ¨æ€APIå‚æ•°ä¼˜åŒ–
window.GLM_TRANSLATE_CONFIG.getOptimalParams = function(textLength) {{
  return {{
    temperature: textLength < 20 ? 0.1 : 0.2,
    max_tokens: Math.min(Math.max(textLength * 2, 50), 800),
    top_p: 0.85,
    frequency_penalty: 0.1,
    presence_penalty: 0.1
  }};
}};

// æ™ºèƒ½æç¤ºè¯ç”Ÿæˆ - ä¼˜åŒ–ï¼šå§‹ç»ˆä»ä¸­æ–‡ç¿»è¯‘ï¼Œæå‡è´¨é‡å’Œé€Ÿåº¦
window.GLM_TRANSLATE_CONFIG.generatePrompt = function(text, targetLang) {{
  const isEnglish = targetLang === 'english';
  const isShort = text.length < 20;
  const isTechnical = /æŠ€æœ¯|ä»£ç |å¼€å‘|ç¼–ç¨‹|ç®—æ³•/.test(text);
  
  if (isEnglish) {{
    if (isShort) return `Translate this Chinese text to English: ${{text}}`;
    if (isTechnical) return `Translate this technical Chinese text to natural English, keeping technical terms accurate:\n\n${{text}}`;
    return `Translate this Chinese text to natural, fluent English:\n\n${{text}}`;
  }} else {{
    const targetLanguage = this.getLanguageName(targetLang);
    if (isShort) return `è¯·å°†è¿™æ®µä¸­æ–‡ç¿»è¯‘ä¸º${{targetLanguage}}ï¼š${{text}}`;
    return `è¯·å°†ä»¥ä¸‹ä¸­æ–‡ç¿»è¯‘ä¸ºè‡ªç„¶æµç•…çš„${{targetLanguage}}ï¼Œä¿æŒåŸæ„å’Œè¯­å¢ƒï¼š\n\n${{text}}`;
  }}
}};

// è¯­è¨€åç§°æ˜ å°„
window.GLM_TRANSLATE_CONFIG.getLanguageName = function(langCode) {{
  const langMap = {{
    'chinese_simplified': 'ç®€ä½“ä¸­æ–‡',
    'chinese_traditional': 'ç¹ä½“ä¸­æ–‡',
    'english': 'English',
    'korean': 'í•œêµ­ì–´',
    'japanese': 'æ—¥æœ¬èª',
    'arabic': 'Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©',
    'deutsch': 'Deutsch',
    'french': 'FranÃ§ais',
    'spanish': 'EspaÃ±ol',
    'portuguese': 'PortuguÃªs'
  }};
  return langMap[langCode] || langCode;
}};

// é«˜çº§æ€§èƒ½ç›‘æ§
window.GLM_TRANSLATE_CONFIG.updateMetrics = function(success, responseTime) {{
  this.metrics.requestCount++;
  if (success) {{
    this.metrics.successCount++;
  }} else {{
    this.metrics.errorCount++;
  }}
  
  // è®¡ç®—å¹³å‡å“åº”æ—¶é—´
  const totalTime = this.metrics.averageResponseTime * (this.metrics.requestCount - 1) + responseTime;
  this.metrics.averageResponseTime = totalTime / this.metrics.requestCount;
  
  if (this.enableDebugLog) {{
    console.log('ç¿»è¯‘æ€§èƒ½æŒ‡æ ‡:', this.metrics);
  }}
}};

// è‡ªé€‚åº”æ‰¹å¤„ç†å¤§å°è°ƒæ•´
window.GLM_TRANSLATE_CONFIG.adjustBatchSize = function(responseTime, errorRate) {{
  if (!this.dynamicBatchAdjustment) return this.batchSize;
  
  if (errorRate > 0.1 || responseTime > this.timeout * 0.8) {{
    // é™ä½æ‰¹å¤„ç†å¤§å°
    this.batchSize = Math.max(this.minBatchSize, Math.floor(this.batchSize * 0.8));
  }} else if (errorRate < 0.05 && responseTime < this.timeout * 0.5) {{
    // å¢åŠ æ‰¹å¤„ç†å¤§å°
    this.batchSize = Math.min(this.maxBatchSize, Math.ceil(this.batchSize * 1.2));
  }}
  
  return this.batchSize;
}};

// æ™ºèƒ½é‡è¯•ç­–ç•¥
window.GLM_TRANSLATE_CONFIG.getRetryDelay = function(attempt, error) {{
  if (!this.intelligentRetry) return this.batchDelay * attempt;
  
  // æ ¹æ®é”™è¯¯ç±»å‹è°ƒæ•´é‡è¯•å»¶è¿Ÿ
  const baseDelay = this.batchDelay;
  let multiplier = Math.pow(2, attempt - 1); // æŒ‡æ•°é€€é¿
  
  if (error && error.status === 429) {{
    // é€Ÿç‡é™åˆ¶é”™è¯¯ï¼Œä½¿ç”¨æ›´é•¿çš„å»¶è¿Ÿ
    multiplier *= 3;
  }} else if (error && error.status >= 500) {{
    // æœåŠ¡å™¨é”™è¯¯ï¼Œä½¿ç”¨ä¸­ç­‰å»¶è¿Ÿ
    multiplier *= 2;
  }}
  
  return Math.min(baseDelay * multiplier, 10000); // æœ€å¤§10ç§’
}};

// ç¼“å­˜ç®¡ç†
window.GLM_TRANSLATE_CONFIG.cache = new Map();
window.GLM_TRANSLATE_CONFIG.getCacheKey = function(text, targetLang) {{
  return `${{text.slice(0, 50)}}_${{targetLang}}`;
}};

window.GLM_TRANSLATE_CONFIG.getFromCache = function(text, targetLang) {{
  if (!this.cacheEnabled) return null;
  const key = this.getCacheKey(text, targetLang);
  const cached = this.cache.get(key);
  if (cached && Date.now() - cached.timestamp < 3600000) {{ // 1å°æ—¶è¿‡æœŸ
    this.metrics.cacheHitRate = (this.metrics.cacheHitRate * this.metrics.requestCount + 1) / (this.metrics.requestCount + 1);
    return cached.result;
  }}
  return null;
}};

window.GLM_TRANSLATE_CONFIG.setCache = function(text, targetLang, result) {{
  if (!this.cacheEnabled) return;
  const key = this.getCacheKey(text, targetLang);
  this.cache.set(key, {{
    result: result,
    timestamp: Date.now()
  }});
  
  // é™åˆ¶ç¼“å­˜å¤§å°
  if (this.cache.size > 1000) {{
    const firstKey = this.cache.keys().next().value;
    this.cache.delete(firstKey);
  }}
}};
"""
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs('docs/javascripts', exist_ok=True)
    
    # å†™å…¥é…ç½®æ–‡ä»¶
    config_path = 'docs/javascripts/translate-config.js'
    with open(config_path, 'w', encoding='utf-8') as f:
        f.write(js_config)
    
    print(f"âœ… ç¿»è¯‘é…ç½®å·²ç”Ÿæˆ: {config_path}")
    print(f"ğŸ“Š é…ç½®å“ˆå¸Œ: {config_hash}")
    print(f"ğŸŒ è¿è¡Œç¯å¢ƒ: {secure_config['environment']}")
    print(f"âš¡ æ€§èƒ½é…ç½®: æ‰¹å¤„ç†={secure_config['batchSize']}, å¹¶å‘={secure_config['maxConcurrent']}, è¶…æ—¶={secure_config['timeout']}ms")
    print(f"ğŸ”§ é«˜çº§ç‰¹æ€§: è‡ªé€‚åº”æ‰¹å¤„ç†={secure_config['adaptiveBatching']}, æ™ºèƒ½é‡è¯•={secure_config['intelligentRetry']}, ç¼“å­˜={secure_config['cacheEnabled']}")
    
    return True

def create_config():
    """ä¿æŒå‘åå…¼å®¹çš„é…ç½®åˆ›å»ºå‡½æ•°"""
    return create_advanced_config()

def export_config_json(config: Dict[str, Any], output_path: Optional[str] = None) -> bool:
    """å¯¼å‡ºé…ç½®ä¸ºJSONæ–‡ä»¶ï¼ˆç”¨äºå¤‡ä»½å’Œè°ƒè¯•ï¼‰"""
    try:
        if output_path is None:
            output_path = os.path.join(os.path.dirname(__file__), '..', 'docs', 'overrides', 'partials', 'translate-config.json')
        
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        # ç§»é™¤æ•æ„Ÿä¿¡æ¯
        safe_config = {k: v for k, v in config.items() if not k.startswith('_')}
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(safe_config, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… JSONé…ç½®å·²å¯¼å‡º: {output_path}")
        return True
    except Exception as e:
        print(f"âŒ JSONé…ç½®å¯¼å‡ºå¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°ï¼Œæ”¯æŒå‘½ä»¤è¡Œå‚æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ç”Ÿæˆé«˜æ€§èƒ½æ™ºèƒ½ç¿»è¯‘é…ç½®')
    parser.add_argument('--env', choices=['development', 'production', 'testing'], 
                       help='æŒ‡å®šè¿è¡Œç¯å¢ƒ')
    parser.add_argument('--profile', choices=['conservative', 'balanced', 'high_performance'], 
                       help='æŒ‡å®šæ€§èƒ½é…ç½®')
    parser.add_argument('--debug', action='store_true', help='å¯ç”¨è°ƒè¯•æ¨¡å¼')
    parser.add_argument('--export-json', action='store_true', help='åŒæ—¶å¯¼å‡ºJSONé…ç½®æ–‡ä»¶')
    parser.add_argument('--validate-only', action='store_true', help='ä»…éªŒè¯é…ç½®ï¼Œä¸ç”Ÿæˆæ–‡ä»¶')
    
    args = parser.parse_args()
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    if args.env:
        os.environ['NODE_ENV'] = args.env
    if args.profile:
        os.environ['PERFORMANCE_PROFILE'] = args.profile
    if args.debug:
        os.environ['DEBUG'] = 'true'
    
    print("ğŸš€ å¼€å§‹ç”Ÿæˆç¿»è¯‘é…ç½®...")
    print(f"ğŸ“Š ç¯å¢ƒ: {os.getenv('NODE_ENV', 'development')}")
    print(f"âš¡ æ€§èƒ½é…ç½®: {os.getenv('PERFORMANCE_PROFILE', 'balanced')}")
    print(f"ğŸ› è°ƒè¯•æ¨¡å¼: {os.getenv('DEBUG', 'false')}")
    print("-" * 50)
    
    try:
        # åˆ›å»ºé…ç½®
        config, _ = create_advanced_config()
        
        # éªŒè¯é…ç½®
        if not validate_config(config):
            print("âŒ é…ç½®éªŒè¯å¤±è´¥")
            return False
        
        if args.validate_only:
            print("âœ… é…ç½®éªŒè¯é€šè¿‡ï¼Œæœªç”Ÿæˆæ–‡ä»¶")
            return True
        
        # ç”Ÿæˆé…ç½®æ–‡ä»¶
        success = generate_secure_config()
        
        if success and args.export_json:
            export_config_json(config)
        
        if success:
            print("\nğŸ‰ ç¿»è¯‘é…ç½®ç”ŸæˆæˆåŠŸï¼")
            print("ğŸ“ é…ç½®æ–‡ä»¶å·²ä¿å­˜åˆ°: docs/javascripts/translate-config.js")
            print("ğŸ”§ ç°åœ¨å¯ä»¥åœ¨ç½‘ç«™ä¸­ä½¿ç”¨é«˜æ€§èƒ½ç¿»è¯‘åŠŸèƒ½äº†")
            print("\nğŸ“ˆ é…ç½®æ‘˜è¦:")
            print(f"   - æ‰¹å¤„ç†å¤§å°: {config['batchSize']}")
            print(f"   - æœ€å¤§å¹¶å‘: {config['maxConcurrent']}")
            print(f"   - è¶…æ—¶æ—¶é—´: {config['timeout']}ms")
            print(f"   - è‡ªé€‚åº”æ‰¹å¤„ç†: {config['adaptiveBatching']}")
            print(f"   - æ™ºèƒ½é‡è¯•: {config['intelligentRetry']}")
            print(f"   - ç¼“å­˜å¯ç”¨: {config['cacheEnabled']}")
            print(f"   - å‹ç¼©å¯ç”¨: {config['compressionEnabled']}")
            print(f"   - æ€§èƒ½ç›‘æ§: {config['performanceTracking']}")
        else:
            print("\nâŒ ç¿»è¯‘é…ç½®ç”Ÿæˆå¤±è´¥")
            return False
            
        return True
        
    except Exception as e:
        print(f"\nâŒ ç”Ÿæˆé…ç½®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        if args.debug:
            import traceback
            traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)